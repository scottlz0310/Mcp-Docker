#!/usr/bin/env python3
"""GitHub Actions Simulator - Click/Rich ãƒ™ãƒ¼ã‚¹ CLI"""

from __future__ import annotations

import json

from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, Iterable, List, cast

import click
import tomllib
from rich.console import Console
from rich.rule import Rule
from rich.table import Table

# ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰ç”¨ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from fastapi import FastAPI, HTTPException
    from fastapi.responses import JSONResponse, HTMLResponse
    import uvicorn

    FASTAPI_AVAILABLE = True
except ImportError:
    FASTAPI_AVAILABLE = False

from . import DEFAULT_CONFIG_PATH, __version__ as simulator_version
from .logger import ActionsLogger
from .service import (
    SimulationParameters,
    SimulationResult,
    SimulationService,
    SimulationServiceError,
)
from .workflow_parser import WorkflowParseError, WorkflowParser
from .output import (
    ensure_subdir,
    generate_run_id,
    load_summary,
    relative_to_output,
    save_json_payload,
    write_log,
)
from .diagnostic import DiagnosticService, DiagnosticStatus


class CLIContext:
    """CLI å…¨ä½“ã§å…±æœ‰ã™ã‚‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã€‚"""

    def __init__(
        self,
        *,
        verbose: bool = False,
        quiet: bool = False,
        debug: bool = False,
        config_path: Path | None = None,
    ) -> None:
        self.verbose = verbose or debug
        self.quiet = quiet
        self.debug = debug
        default_config = DEFAULT_CONFIG_PATH if DEFAULT_CONFIG_PATH.exists() else None
        self._default_config_path = default_config
        self.config_path = config_path or default_config
        self.config_data: dict[str, Any] = {}
        self.logger: ActionsLogger | None = None
        self.service: SimulationService | None = None
        self._config_warning_emitted = False
        self.console: Console = Console(
            quiet=self.quiet,
            highlight=not self.quiet,
        )

    def reconfigure(
        self,
        *,
        verbose: bool | None = None,
        quiet: bool | None = None,
        debug: bool | None = None,
        config_path: Path | None = None,
    ) -> None:
        if verbose is not None:
            self.verbose = verbose or (debug or False)
        if quiet is not None:
            self.quiet = quiet
        if debug is not None:
            self.debug = debug
            if debug:
                self.verbose = True
        if config_path is not None:
            resolved = config_path
            if resolved != self.config_path:
                self.config_path = resolved
                self.config_data = {}
                self.service = None
                self._config_warning_emitted = False
        elif self.config_path is None and self._default_config_path is not None:
            self.config_path = self._default_config_path

        # ãƒ¢ãƒ¼ãƒ‰å¤‰æ›´æ™‚ã¯ãƒ­ã‚¬ãƒ¼ã¨ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã‚’å†åˆæœŸåŒ–ã™ã‚‹
        self.console = Console(
            quiet=self.quiet,
            highlight=not self.quiet,
        )
        self.logger = None

    def load_config(self) -> None:
        if not self.config_path:
            self.config_data = {}
            return
        if self.config_data:
            return

        try:
            with self.config_path.open("rb") as handle:
                self.config_data = tomllib.load(handle)
                self.service = None
        except FileNotFoundError:
            if not self._config_warning_emitted:
                self.console.print(f"[yellow]è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.config_path}[/yellow]")
                self._config_warning_emitted = True
            self.config_data = {}
            self.service = None
        except tomllib.TOMLDecodeError as exc:
            if not self._config_warning_emitted:
                self.console.print(f"[red]è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}[/red]")
                self._config_warning_emitted = True
            self.config_data = {}
            self.service = None


def _parse_env_assignments(assignments: Iterable[str]) -> Dict[str, str]:
    env: Dict[str, str] = {}
    for raw in assignments:
        if "=" not in raw:
            raise click.BadParameter(
                f"ç„¡åŠ¹ãªç’°å¢ƒå¤‰æ•°å½¢å¼ã§ã™: '{raw}'. KEY=VALUE å½¢å¼ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚",
                param_hint="--env",
            )
        key, value = raw.split("=", 1)
        key = key.strip()
        if not key:
            raise click.BadParameter(
                f"ç’°å¢ƒå¤‰æ•°åãŒç©ºã§ã™: '{raw}'",
                param_hint="--env",
            )
        env[key] = value
    return env


def _build_context(
    ctx: click.Context,
    *,
    verbose: bool | None = None,
    quiet: bool | None = None,
    debug: bool | None = None,
) -> CLIContext:
    """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«ãƒ­ã‚¬ãƒ¼ã‚’è¨­å®šã—ã¦è¿”ã™ã€‚"""

    context = ctx.ensure_object(CLIContext)

    if any(value is not None for value in (verbose, quiet, debug)):
        context.reconfigure(
            verbose=context.verbose if verbose is None else verbose,
            quiet=context.quiet if quiet is None else quiet,
            debug=context.debug if debug is None else debug,
        )

    if context.logger is None:
        context.logger = ActionsLogger(
            verbose=context.verbose,
            quiet=context.quiet,
            debug=context.debug,
        )

    if context.service is None:
        context.service = SimulationService()

    return context


def run_simulate(
    workflow_file: Path,
    job: str | None,
    env_file: Path | None,
    dry_run: bool,
    logger: ActionsLogger,
    console: Console,
    env_vars: Dict[str, str] | None,
    *,
    service: SimulationService,
    create_debug_bundle: bool = False,
    debug_bundle_dir: Path | None = None,
    show_performance_metrics: bool = False,
    show_execution_trace: bool = False,
) -> SimulationResult:
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰ã®å‡¦ç†"""

    params = SimulationParameters(
        workflow_file=workflow_file,
        job=job,
        dry_run=dry_run,
        env_file=env_file,
        verbose=logger.verbose,
        env_vars=env_vars,
    )

    try:
        result = service.run_simulation(
            params,
            logger=logger,
            capture_output=True,
        )

        # è©³ç´°çµæœã®è¡¨ç¤ºå‡¦ç†
        if hasattr(result, "detailed_result") and result.detailed_result:
            detailed_result = result.detailed_result

            # è¨ºæ–­çµæœã®è¡¨ç¤º
            if hasattr(detailed_result, "diagnostic_results") and detailed_result.diagnostic_results:
                console.print("\n[cyan]ğŸ“‹ è¨ºæ–­çµæœ:[/cyan]")
                for diag_result in detailed_result.diagnostic_results:
                    status_icon = {"OK": "âœ…", "WARNING": "âš ï¸", "ERROR": "âŒ"}.get(
                        diag_result.status.value if hasattr(diag_result.status, "value") else str(diag_result.status),
                        "â“",
                    )

                    console.print(f"  {status_icon} {diag_result.component}: {diag_result.message}")

                    if diag_result.recommendations:
                        for rec in diag_result.recommendations[:2]:  # æœ€åˆã®2ã¤ã®æ¨å¥¨äº‹é …ã®ã¿è¡¨ç¤º
                            console.print(f"    ğŸ’¡ {rec}")

            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¡¨ç¤º
            if (
                show_performance_metrics
                and hasattr(detailed_result, "performance_metrics")
                and detailed_result.performance_metrics
            ):
                console.print("\n[cyan]ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹:[/cyan]")
                metrics = detailed_result.performance_metrics

                if hasattr(metrics, "execution_time_ms"):
                    console.print(f"  â±ï¸  å®Ÿè¡Œæ™‚é–“: {metrics.execution_time_ms:.2f}ms")
                if hasattr(metrics, "peak_memory_mb"):
                    console.print(f"  ğŸ§  ãƒ”ãƒ¼ã‚¯ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {metrics.peak_memory_mb:.2f}MB")
                if hasattr(metrics, "cpu_usage_percent"):
                    console.print(f"  âš¡ CPUä½¿ç”¨ç‡: {metrics.cpu_usage_percent:.1f}%")
                if hasattr(metrics, "docker_operations_count"):
                    console.print(f"  ğŸ³ Dockeræ“ä½œæ•°: {metrics.docker_operations_count}")

            # å®Ÿè¡Œãƒˆãƒ¬ãƒ¼ã‚¹ã®è¡¨ç¤º
            if show_execution_trace and hasattr(detailed_result, "execution_trace") and detailed_result.execution_trace:
                console.print("\n[cyan]ğŸ” å®Ÿè¡Œãƒˆãƒ¬ãƒ¼ã‚¹:[/cyan]")
                trace = detailed_result.execution_trace

                if hasattr(trace, "stages") and trace.stages:
                    for stage in trace.stages[-5:]:  # æœ€å¾Œã®5æ®µéšã®ã¿è¡¨ç¤º
                        stage_name = stage.stage.value if hasattr(stage.stage, "value") else str(stage.stage)
                        duration = (
                            f" ({stage.duration_ms:.2f}ms)"
                            if hasattr(stage, "duration_ms") and stage.duration_ms
                            else ""
                        )
                        console.print(f"  ğŸ“ {stage_name}{duration}")

            # ãƒãƒ³ã‚°ã‚¢ãƒƒãƒ—æ¤œå‡ºã¨ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤ºã®å‡¦ç†
            if detailed_result.hang_analysis or (
                hasattr(detailed_result, "error_report") and detailed_result.error_report
            ):
                console.print("[yellow]âš ï¸  ãƒãƒ³ã‚°ã‚¢ãƒƒãƒ—ã¾ãŸã¯å®Ÿè¡Œå•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ[/yellow]")

                # è©³ç´°ãªãƒãƒ³ã‚°ã‚¢ãƒƒãƒ—åˆ†æã®è¡¨ç¤º
                if detailed_result.hang_analysis:
                    analysis = detailed_result.hang_analysis
                    console.print(f"[yellow]ğŸ“‹ åˆ†æID: {analysis.analysis_id}[/yellow]")

                    if analysis.primary_cause:
                        console.print(f"[red]ğŸš¨ ä¸»è¦ãªå•é¡Œ: {analysis.primary_cause.title}[/red]")
                        console.print(f"[red]   èª¬æ˜: {analysis.primary_cause.description}[/red]")
                        console.print(
                            f"[red]   é‡è¦åº¦: {analysis.primary_cause.severity.value if hasattr(analysis.primary_cause.severity, 'value') else analysis.primary_cause.severity}[/red]"
                        )

                        # æ¨å¥¨äº‹é …ã®è¡¨ç¤º
                        if (
                            hasattr(analysis.primary_cause, "recommendations")
                            and analysis.primary_cause.recommendations
                        ):
                            console.print("[cyan]ğŸ’¡ æ¨å¥¨ã•ã‚Œã‚‹å¯¾å‡¦æ³•:[/cyan]")
                            for i, rec in enumerate(analysis.primary_cause.recommendations[:3], 1):
                                console.print(f"   {i}. {rec}")

                        # ä¿®æ­£ã‚³ãƒãƒ³ãƒ‰ã®è¡¨ç¤º
                        if hasattr(analysis.primary_cause, "fix_commands") and analysis.primary_cause.fix_commands:
                            console.print("[green]ğŸ”§ ä¿®æ­£ã‚³ãƒãƒ³ãƒ‰:[/green]")
                            for cmd in analysis.primary_cause.fix_commands[:2]:
                                console.print(f"   $ {cmd}")

                    # å¾©æ—§ææ¡ˆã®è¡¨ç¤º
                    if hasattr(analysis, "recovery_suggestions") and analysis.recovery_suggestions:
                        console.print("[blue]ğŸ”„ å¾©æ—§ææ¡ˆ:[/blue]")
                        for i, suggestion in enumerate(analysis.recovery_suggestions[:3], 1):
                            console.print(f"   {i}. {suggestion}")

                    # äºˆé˜²ç­–ã®è¡¨ç¤º
                    if hasattr(analysis, "prevention_measures") and analysis.prevention_measures:
                        console.print("[magenta]ğŸ›¡ï¸  äºˆé˜²ç­–:[/magenta]")
                        for i, measure in enumerate(analysis.prevention_measures[:2], 1):
                            console.print(f"   {i}. {measure}")

                # ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã®è©³ç´°è¡¨ç¤º
                if hasattr(detailed_result, "error_report") and detailed_result.error_report:
                    error_report = detailed_result.error_report
                    console.print(f"[dim]ğŸ“„ ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆID: {error_report.report_id}[/dim]")

                    # ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¬ã‚¤ãƒ‰ã®è¡¨ç¤º
                    if hasattr(error_report, "troubleshooting_guide") and error_report.troubleshooting_guide:
                        console.print("[cyan]ğŸ“– ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¬ã‚¤ãƒ‰:[/cyan]")
                        for i, step in enumerate(error_report.troubleshooting_guide[:3], 1):
                            console.print(f"   {i}. {step}")

                    # æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã®è¡¨ç¤º
                    if hasattr(error_report, "next_steps") and error_report.next_steps:
                        console.print("[yellow]â¡ï¸  æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:[/yellow]")
                        for i, step in enumerate(error_report.next_steps[:3], 1):
                            console.print(f"   {i}. {step}")

                # ãƒ‡ãƒãƒƒã‚°ãƒãƒ³ãƒ‰ãƒ«ã®è‡ªå‹•ä½œæˆ
                # TODO: ãƒ‡ãƒãƒƒã‚°ãƒãƒ³ãƒ‰ãƒ«ä½œæˆæ©Ÿèƒ½ã¯ç¾åœ¨HangupDetectorã«ç§»è¡Œã•ã‚Œã¦ã„ã¾ã™
                # EnhancedActWrapperã®create_debug_bundle_for_hangupãƒ¡ã‚½ãƒƒãƒ‰ã¯å­˜åœ¨ã—ã¾ã›ã‚“
                if (
                    False  # type: ignore[unreachable]
                    and create_debug_bundle
                    and hasattr(detailed_result, "error_report")
                    and detailed_result.error_report
                ):
                    try:  # type: ignore[unreachable]
                        from .enhanced_act_wrapper import EnhancedActWrapper

                        if hasattr(service, "act_wrapper") and isinstance(service.act_wrapper, EnhancedActWrapper):
                            console.print("[blue]ğŸ”§ ãƒ‡ãƒãƒƒã‚°ãƒãƒ³ãƒ‰ãƒ«ã‚’ä½œæˆä¸­...[/blue]")

                            # debug_bundle = service.act_wrapper.create_debug_bundle_for_hangup(
                            #     error_report=detailed_result.error_report,
                            #     output_directory=debug_bundle_dir,
                            # )

                            debug_bundle = None
                            if debug_bundle and hasattr(debug_bundle, "bundle_path") and debug_bundle.bundle_path:
                                console.print(
                                    f"[green]âœ… ãƒ‡ãƒãƒƒã‚°ãƒãƒ³ãƒ‰ãƒ«ãŒä½œæˆã•ã‚Œã¾ã—ãŸ: {debug_bundle.bundle_path}[/green]"
                                )
                                if hasattr(debug_bundle, "total_size_bytes"):
                                    console.print(f"[green]   ã‚µã‚¤ã‚º: {debug_bundle.total_size_bytes} bytes[/green]")
                                if hasattr(debug_bundle, "included_files"):
                                    console.print(
                                        f"[green]   å«ã¾ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«: {len(debug_bundle.included_files)}å€‹[/green]"
                                    )

                                # ãƒ‡ãƒãƒƒã‚°ãƒãƒ³ãƒ‰ãƒ«ã®ä½¿ç”¨æ–¹æ³•ã‚’æ¡ˆå†…
                                console.print(
                                    "[dim]ğŸ’¡ ã“ã®ãƒ‡ãƒãƒƒã‚°ãƒãƒ³ãƒ‰ãƒ«ã‚’æŠ€è¡“ã‚µãƒãƒ¼ãƒˆã«é€ä¿¡ã—ã¦è©³ç´°ãªåˆ†æã‚’ä¾é ¼ã§ãã¾ã™[/dim]"
                                )
                            else:
                                console.print("[red]âŒ ãƒ‡ãƒãƒƒã‚°ãƒãƒ³ãƒ‰ãƒ«ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ[/red]")
                    except Exception as e:
                        logger.error(f"ãƒ‡ãƒãƒƒã‚°ãƒãƒ³ãƒ‰ãƒ«ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                        console.print(f"[red]âŒ ãƒ‡ãƒãƒƒã‚°ãƒãƒ³ãƒ‰ãƒ«ä½œæˆã‚¨ãƒ©ãƒ¼: {e}[/red]")

    except SimulationServiceError as exc:
        logger.error(str(exc))
        return SimulationResult(
            success=False,
            return_code=1,
            stderr=str(exc),
        )

    if result.stdout:
        console.print(result.stdout.rstrip("\n"), markup=False)
    if result.stderr:
        console.print(result.stderr.rstrip("\n"), style="red", markup=False)

    return result


def run_validate(
    workflow_file: Path,
    strict: bool,
    logger: ActionsLogger,
) -> int:
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ¤œè¨¼ã‚³ãƒãƒ³ãƒ‰ã®å‡¦ç†"""

    if not workflow_file.exists():
        logger.error(f"ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {workflow_file}")
        return 1

    targets: List[Path]
    if workflow_file.is_dir():
        yaml_files = set(workflow_file.rglob("*.yml")) | set(workflow_file.rglob("*.yaml"))
        targets = sorted(yaml_files)
        if not targets:
            logger.warning(f"æ¤œè¨¼å¯¾è±¡ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {workflow_file}")
            return 1
    else:
        targets = [workflow_file]

    overall_success = True
    for target in targets:
        logger.info(f"ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ¤œè¨¼ä¸­: {target}")
        parser = WorkflowParser()
        try:
            workflow = parser.parse_file(target)
            if strict:
                parser.strict_validate(workflow)
            logger.success(f"{target} ã®æ¤œè¨¼ãŒå®Œäº†ã—ã¾ã—ãŸ âœ“")
        except WorkflowParseError as exc:
            overall_success = False
            logger.error(f"{target} ã®æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {exc}")

    return 0 if overall_success else 1


def run_list_jobs(
    workflow_file: Path,
    output_format: str,
    logger: ActionsLogger,
    console: Console,
) -> int:
    """ã‚¸ãƒ§ãƒ–ä¸€è¦§è¡¨ç¤ºã‚³ãƒãƒ³ãƒ‰ã®å‡¦ç†"""

    if not workflow_file.exists():
        logger.error(f"ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {workflow_file}")
        return 1

    # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è§£æ
    parser = WorkflowParser()
    try:
        workflow = parser.parse_file(workflow_file)
    except WorkflowParseError as exc:
        logger.error(f"ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è§£æã‚¨ãƒ©ãƒ¼: {exc}")
        return 1

    jobs = workflow.get("jobs", {})

    if output_format.lower() == "json":
        jobs_info: list[dict[str, Any]] = []
        for job_id, job_data in jobs.items():
            jobs_info.append(
                {
                    "job_id": job_id,
                    "name": job_data.get("name", job_id),
                    "runs_on": job_data.get("runs-on", "unknown"),
                    "steps": len(job_data.get("steps", [])),
                }
            )
        console.print_json(data=jobs_info)
    else:
        table = Table(title="ã‚¸ãƒ§ãƒ–ä¸€è¦§", show_lines=True)
        table.add_column("Job ID", style="cyan", no_wrap=True)
        table.add_column("Name", style="green")
        table.add_column("Runs on", style="magenta")
        table.add_column("Steps", style="yellow")

        for job_id, job_data in jobs.items():
            job_name = job_data.get("name", job_id)
            runs_on = job_data.get("runs-on", "unknown")
            steps_count = len(job_data.get("steps", []))
            table.add_row(job_id, job_name, runs_on, str(steps_count))

        console.print(table)

    return 0


def run_diagnose(
    logger: ActionsLogger,
    console: Console,
    output_format: str,
    output_file: Path | None,
    include_performance_analysis: bool = False,
    include_trace_analysis: bool = False,
) -> int:
    """ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­ã‚³ãƒãƒ³ãƒ‰ã®å‡¦ç†"""

    logger.info("GitHub Actions Simulatorã®ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­ã‚’é–‹å§‹ã—ã¾ã™...")

    # è¨ºæ–­ã‚µãƒ¼ãƒ“ã‚¹ã‚’åˆæœŸåŒ–
    diagnostic_service = DiagnosticService(logger=logger)

    # åŒ…æ‹¬çš„ãªãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ
    health_report = diagnostic_service.run_comprehensive_health_check()

    # ãƒãƒ³ã‚°ã‚¢ãƒƒãƒ—ã®æ½œåœ¨çš„åŸå› ã‚’ç‰¹å®š
    hangup_causes = diagnostic_service.identify_hangup_causes()

    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    performance_analysis: dict[str, Any] = {}
    if include_performance_analysis:
        logger.info("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã‚’å®Ÿè¡Œä¸­...")
        try:
            # ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ã®è©³ç´°åˆ†æ
            import psutil

            performance_analysis = {
                "cpu_count": psutil.cpu_count(),
                "cpu_percent": psutil.cpu_percent(interval=1),
                "memory_total_gb": round(psutil.virtual_memory().total / (1024**3), 2),
                "memory_available_gb": round(psutil.virtual_memory().available / (1024**3), 2),
                "disk_usage_percent": psutil.disk_usage("/").percent,
                "load_average": psutil.getloadavg() if hasattr(psutil, "getloadavg") else None,
            }
        except Exception as e:
            logger.warning(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            performance_analysis = {"error": str(e)}

    # ãƒˆãƒ¬ãƒ¼ã‚¹åˆ†æï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    trace_analysis: dict[str, Any] = {}
    if include_trace_analysis:
        logger.info("å®Ÿè¡Œãƒˆãƒ¬ãƒ¼ã‚¹åˆ†æã‚’å®Ÿè¡Œä¸­...")
        try:
            # æœ€è¿‘ã®å®Ÿè¡Œãƒ­ã‚°ã®åˆ†æ
            from pathlib import Path

            output_dir = Path("output")
            if output_dir.exists():
                log_files = list(output_dir.rglob("*.log"))
                trace_analysis = {
                    "recent_log_files": len(log_files),
                    "latest_logs": [
                        str(f) for f in sorted(log_files, key=lambda x: x.stat().st_mtime, reverse=True)[:5]
                    ],
                }
            else:
                trace_analysis = {
                    "log_files": 0,
                    "message": "å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“",
                }
        except Exception as e:
            logger.warning(f"ãƒˆãƒ¬ãƒ¼ã‚¹åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            trace_analysis = {"error": str(e)}

    # çµæœã®å‡ºåŠ›
    if output_format.lower() == "json":
        # JSONå½¢å¼ã§ã®å‡ºåŠ›
        json_data: dict[str, Any] = {
            "overall_status": health_report.overall_status.value,
            "summary": health_report.summary,
            "timestamp": health_report.timestamp,
            "results": [
                {
                    "component": result.component,
                    "status": result.status.value,
                    "message": result.message,
                    "details": result.details,
                    "recommendations": result.recommendations,
                    "timestamp": result.timestamp,
                }
                for result in health_report.results
            ],
            "potential_hangup_causes": hangup_causes,
        }

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã¨ãƒˆãƒ¬ãƒ¼ã‚¹åˆ†æã‚’è¿½åŠ 
        if performance_analysis:
            json_data["performance_analysis"] = performance_analysis
        if trace_analysis:
            json_data["trace_analysis"] = trace_analysis

        if output_file:
            output_file.write_text(json.dumps(json_data, ensure_ascii=False, indent=2), encoding="utf-8")
            logger.info(f"è¨ºæ–­çµæœã‚’ {output_file} ã«ä¿å­˜ã—ã¾ã—ãŸ")

        console.print_json(data=json_data)
    else:
        # ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§ã®å‡ºåŠ›
        console.print(Rule("ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­çµæœ"))

        # å…¨ä½“çš„ãªã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
        status_icon = {
            DiagnosticStatus.OK: "âœ…",
            DiagnosticStatus.WARNING: "âš ï¸",
            DiagnosticStatus.ERROR: "âŒ",
        }.get(health_report.overall_status, "â“")

        console.print(f"{status_icon} å…¨ä½“çš„ãªã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {health_report.overall_status.value}")
        console.print(f"ğŸ“‹ {health_report.summary}")
        console.print()

        # è©³ç´°çµæœã®ãƒ†ãƒ¼ãƒ–ãƒ«
        table = Table(title="è©³ç´°è¨ºæ–­çµæœ", show_lines=True)
        table.add_column("ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ", style="cyan", no_wrap=True)
        table.add_column("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", style="bold")
        table.add_column("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸", style="white")
        table.add_column("æ¨å¥¨äº‹é …", style="yellow")

        for result in health_report.results:
            status_style = {
                DiagnosticStatus.OK: "green",
                DiagnosticStatus.WARNING: "yellow",
                DiagnosticStatus.ERROR: "red",
            }.get(result.status, "white")

            recommendations_text = "\n".join(result.recommendations) if result.recommendations else "-"

            table.add_row(
                result.component,
                f"[{status_style}]{result.status.value}[/]",
                result.message,
                recommendations_text,
            )

        console.print(table)

        # ãƒãƒ³ã‚°ã‚¢ãƒƒãƒ—ã®æ½œåœ¨çš„åŸå› ã¨å¾©æ—§ææ¡ˆ
        if hangup_causes:
            console.print()
            console.print(Rule("ãƒãƒ³ã‚°ã‚¢ãƒƒãƒ—ã®æ½œåœ¨çš„åŸå› ã¨å¾©æ—§ææ¡ˆ"))
            for i, cause in enumerate(hangup_causes, 1):
                console.print(f"{i}. {cause}")

            # å¾©æ—§ææ¡ˆã‚’ç”Ÿæˆ
            recovery_suggestions = _generate_recovery_suggestions_from_causes(hangup_causes, health_report)
            if recovery_suggestions:
                console.print()
                console.print("[cyan]ğŸ”„ æ¨å¥¨ã•ã‚Œã‚‹å¾©æ—§æ‰‹é †:[/cyan]")
                for i, suggestion in enumerate(recovery_suggestions, 1):
                    console.print(f"   {i}. {suggestion}")

        # ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã¨è©³ç´°ãªãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
        error_results = [r for r in health_report.results if r.status == DiagnosticStatus.ERROR]
        if error_results:
            console.print()
            console.print(Rule("ã‚¨ãƒ©ãƒ¼è©³ç´°ã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°"))

            for error_result in error_results:
                console.print(f"[red]âŒ {error_result.component}[/red]")
                console.print(f"   å•é¡Œ: {error_result.message}")

                if error_result.recommendations:
                    console.print("   [yellow]å¯¾å‡¦æ³•:[/yellow]")
                    for rec in error_result.recommendations:
                        console.print(f"     â€¢ {rec}")

                # è©³ç´°æƒ…å ±ãŒã‚ã‚‹å ´åˆã¯è¡¨ç¤º
                if error_result.details:
                    important_details = _extract_important_details(error_result.details)
                    if important_details:
                        console.print("   [dim]è©³ç´°æƒ…å ±:[/dim]")
                        for key, value in important_details.items():
                            console.print(f"     {key}: {value}")
                console.print()

        # æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã®ææ¡ˆ
        next_steps = _generate_next_steps(health_report, hangup_causes)
        if next_steps:
            console.print()
            console.print(Rule("æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—"))
            console.print("[green]æ¨å¥¨ã•ã‚Œã‚‹æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:[/green]")
            for i, step in enumerate(next_steps, 1):
                console.print(f"   {i}. {step}")

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã®è¡¨ç¤º
        if performance_analysis and "error" not in performance_analysis:
            console.print()
            console.print(Rule("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ"))
            console.print(
                f"ğŸ–¥ï¸  CPU: {performance_analysis.get('cpu_count', 'N/A')}ã‚³ã‚¢, ä½¿ç”¨ç‡: {performance_analysis.get('cpu_percent', 'N/A')}%"
            )
            console.print(
                f"ğŸ§  ãƒ¡ãƒ¢ãƒª: {performance_analysis.get('memory_available_gb', 'N/A')}GBåˆ©ç”¨å¯èƒ½ / {performance_analysis.get('memory_total_gb', 'N/A')}GBç·å®¹é‡"
            )
            console.print(f"ğŸ’¾ ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡: {performance_analysis.get('disk_usage_percent', 'N/A')}%")
            if performance_analysis.get("load_average"):
                load_avg = performance_analysis["load_average"]
                console.print(f"âš¡ ã‚·ã‚¹ãƒ†ãƒ è² è·: {load_avg[0]:.2f}, {load_avg[1]:.2f}, {load_avg[2]:.2f}")

        # ãƒˆãƒ¬ãƒ¼ã‚¹åˆ†æã®è¡¨ç¤º
        if trace_analysis and "error" not in trace_analysis:
            console.print()
            console.print(Rule("å®Ÿè¡Œãƒˆãƒ¬ãƒ¼ã‚¹åˆ†æ"))
            console.print(f"ğŸ“ æœ€è¿‘ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {trace_analysis.get('recent_log_files', 0)}")
            if trace_analysis.get("latest_logs"):
                console.print("ğŸ“‹ æœ€æ–°ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«:")
                for log_file in trace_analysis["latest_logs"][:3]:
                    console.print(f"  â€¢ {log_file}")

        # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
        if output_file:
            json_data = {
                "overall_status": health_report.overall_status.value,
                "summary": health_report.summary,
                "timestamp": health_report.timestamp,
                "results": [
                    {
                        "component": result.component,
                        "status": result.status.value,
                        "message": result.message,
                        "details": result.details,
                        "recommendations": result.recommendations,
                        "timestamp": result.timestamp,
                    }
                    for result in health_report.results
                ],
                "potential_hangup_causes": hangup_causes,
            }

            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã¨ãƒˆãƒ¬ãƒ¼ã‚¹åˆ†æã‚’è¿½åŠ 
            if performance_analysis:
                json_data["performance_analysis"] = performance_analysis
            if trace_analysis:
                json_data["trace_analysis"] = trace_analysis

            output_file.write_text(json.dumps(json_data, ensure_ascii=False, indent=2), encoding="utf-8")
            logger.info(f"è¨ºæ–­çµæœã‚’ {output_file} ã«ä¿å­˜ã—ã¾ã—ãŸ")

    # çµ‚äº†ã‚³ãƒ¼ãƒ‰ã®æ±ºå®š
    if health_report.overall_status == DiagnosticStatus.ERROR:
        return 1
    elif health_report.overall_status == DiagnosticStatus.WARNING:
        return 2
    else:
        return 0


@click.group(
    cls=click.Group,
    context_settings={
        "help_option_names": ["-h", "--help"],
        "max_content_width": 100,
    },
    help="""GitHub Actions Simulator

GitHub Actions ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã§ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ/æ¤œè¨¼ã™ã‚‹ãŸã‚ã®CLIãƒ„ãƒ¼ãƒ«ã§ã™ã€‚

åˆ©ç”¨å¯èƒ½ãªã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰:
  - simulate             ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œã™ã‚‹ï¼ˆ--diagnose ã§äº‹å‰è¨ºæ–­ã€--enhanced ã§æ‹¡å¼µæ©Ÿèƒ½ã€--show-performance-metrics ã§ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤ºï¼‰
  - validate             ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®æ§‹æ–‡ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹
  - list-jobs            ã‚¸ãƒ§ãƒ–ä¸€è¦§ã‚’è¡¨ç¤ºã™ã‚‹
  - diagnose             ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ï¼ˆ--include-performance, --include-trace ã§è©³ç´°åˆ†æï¼‰
  - create-debug-bundle  ãƒ‡ãƒãƒƒã‚°ãƒãƒ³ãƒ‰ãƒ«ã‚’ä½œæˆã™ã‚‹ï¼ˆãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ç”¨ï¼‰
""",
)
@click.option("-v", "--verbose", is_flag=True, help="è©³ç´°ãƒ­ã‚°ã‚’è¡¨ç¤º")
@click.option("-q", "--quiet", is_flag=True, help="æœ€å°é™ã®å‡ºåŠ›ã«åˆ‡ã‚Šæ›¿ãˆã‚‹")
@click.option("--debug", is_flag=True, help="ãƒ‡ãƒãƒƒã‚°ãƒ¬ãƒ™ãƒ«ã®ãƒ­ã‚°ã‚’è¡¨ç¤º")
@click.option(
    "--config",
    type=click.Path(dir_okay=False, path_type=Path),
    help="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« (TOML) ã‚’æŒ‡å®š",
)
@click.version_option(  # pragma: no mutate - CLI è¡¨ç¤ºã®ã¿
    version=simulator_version,
    prog_name="GitHub Actions Simulator",
)
@click.pass_context
def cli(
    ctx: click.Context,
    verbose: bool,
    quiet: bool,
    debug: bool,
    config: Path | None,
) -> None:
    """CLIã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""

    context = ctx.obj if isinstance(ctx.obj, CLIContext) else None
    if context is None:
        context = CLIContext(
            verbose=verbose,
            quiet=quiet,
            debug=debug,
            config_path=config,
        )
    else:
        context.reconfigure(
            verbose=verbose,
            quiet=quiet,
            debug=debug,
            config_path=config,
        )

    ctx.obj = context
    context.load_config()


@cli.command(short_help="ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œ")
@click.argument(
    "workflow_files",
    nargs=-1,
    type=click.Path(path_type=Path),
)
@click.option("--job", help="å®Ÿè¡Œã™ã‚‹ç‰¹å®šã®ã‚¸ãƒ§ãƒ–å")
@click.option(
    "--env-file",
    type=click.Path(dir_okay=False, path_type=Path),
    help="ç’°å¢ƒå¤‰æ•°ãƒ•ã‚¡ã‚¤ãƒ«(.env)",
)
@click.option(
    "--dry-run",
    is_flag=True,
    help="å®Ÿéš›ã«å®Ÿè¡Œã›ãšã«ãƒ—ãƒ©ãƒ³ã‚’è¡¨ç¤º",
)
@click.option(
    "--verbose",
    "simulate_verbose",
    is_flag=True,
    help="è©³ç´°ãƒ­ã‚°ã‚’æœ‰åŠ¹åŒ–",
)
@click.option(
    "--quiet",
    "simulate_quiet",
    is_flag=True,
    help="æ¨™æº–å‡ºåŠ›ã‚’æŠ‘åˆ¶",
)
@click.option(
    "--debug",
    "simulate_debug",
    is_flag=True,
    help="ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã‚’æœ‰åŠ¹åŒ– (verboseã‚’æš—é»™çš„ã«æœ‰åŠ¹åŒ–)",
)
@click.option("--event", "event_name", help="GitHubã‚¤ãƒ™ãƒ³ãƒˆåã‚’æŒ‡å®š")
@click.option("--ref", "git_ref", help="Gitãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã‚’æŒ‡å®š")
@click.option("--actor", help="å®Ÿè¡Œãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’æŒ‡å®š")
@click.option(
    "--env",
    "inline_env",
    multiple=True,
    help="è¿½åŠ ã®ç’°å¢ƒå¤‰æ•°ã‚’ KEY=VALUE å½¢å¼ã§æŒ‡å®š (è¤‡æ•°æŒ‡å®šå¯)",
)
@click.option(
    "--fail-fast",
    is_flag=True,
    help="æœ€åˆã®å¤±æ•—ã§æ®‹ã‚Šã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—",
)
@click.option(
    "--output-format",
    type=click.Choice(["console", "json"], case_sensitive=False),
    default="console",
    show_default=True,
    help="å®Ÿè¡Œã‚µãƒãƒªãƒ¼ã®å‡ºåŠ›å½¢å¼",
)
@click.option(
    "--output-file",
    type=click.Path(dir_okay=False, path_type=Path),
    help="ã‚µãƒãƒªãƒ¼ã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹",
)
@click.option(
    "--enhanced",
    is_flag=True,
    help="æ”¹è‰¯ã•ã‚ŒãŸActWrapperã‚’ä½¿ç”¨ï¼ˆè¨ºæ–­æ©Ÿèƒ½ã¨ãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯æ¤œå‡ºä»˜ãï¼‰",
)
@click.option(
    "--diagnose",
    is_flag=True,
    help="å®Ÿè¡Œå‰ã«ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­ã‚’å®Ÿè¡Œ",
)
@click.option(
    "--create-debug-bundle",
    is_flag=True,
    help="ãƒãƒ³ã‚°ã‚¢ãƒƒãƒ—æ™‚ã«ãƒ‡ãƒãƒƒã‚°ãƒãƒ³ãƒ‰ãƒ«ã‚’è‡ªå‹•ä½œæˆ",
)
@click.option(
    "--debug-bundle-dir",
    type=click.Path(file_okay=False, path_type=Path),
    help="ãƒ‡ãƒãƒƒã‚°ãƒãƒ³ãƒ‰ãƒ«ã®å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª",
)
@click.option(
    "--show-performance-metrics",
    is_flag=True,
    help="ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¡¨ç¤º",
)
@click.option(
    "--show-execution-trace",
    is_flag=True,
    help="å®Ÿè¡Œãƒˆãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’è¡¨ç¤º",
)
@click.pass_context
def simulate(
    ctx: click.Context,
    workflow_files: tuple[Path, ...],
    job: str | None,
    env_file: Path | None,
    dry_run: bool,
    simulate_verbose: bool,
    simulate_quiet: bool,
    simulate_debug: bool,
    event_name: str | None,
    git_ref: str | None,
    actor: str | None,
    inline_env: tuple[str, ...],
    fail_fast: bool,
    output_format: str,
    output_file: Path | None,
    enhanced: bool,
    diagnose: bool,
    create_debug_bundle: bool,
    debug_bundle_dir: Path | None,
    show_performance_metrics: bool,
    show_execution_trace: bool,
) -> None:
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œã™ã‚‹ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰"""

    context = _build_context(
        ctx,
        verbose=True if simulate_verbose else None,
        quiet=True if simulate_quiet else None,
        debug=True if simulate_debug else None,
    )
    logger = context.logger
    assert logger is not None
    console = context.console

    workflow_paths = list(workflow_files)
    if not workflow_paths:
        console.print("[red]ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å°‘ãªãã¨ã‚‚1ã¤æŒ‡å®šã—ã¦ãã ã•ã„ã€‚[/red]")
        raise SystemExit(1)

    env_overrides: Dict[str, str] = {}

    config_env = context.config_data.get("environment")
    if isinstance(config_env, dict):
        typed_env = cast(Dict[str, Any], config_env)
        env_overrides.update({str(key): str(value) for key, value in typed_env.items()})

    simulator_config = context.config_data.get("simulator")
    if isinstance(simulator_config, dict):
        typed_simulator = cast(Dict[str, Any], simulator_config)
        default_event = typed_simulator.get("default_event")
        if isinstance(default_event, str) and not event_name:
            env_overrides.setdefault("GITHUB_EVENT_NAME", default_event)
        default_ref = typed_simulator.get("default_ref")
        if isinstance(default_ref, str) and not git_ref:
            env_overrides.setdefault("GITHUB_REF", default_ref)
        default_actor = typed_simulator.get("default_actor")
        if isinstance(default_actor, str) and not actor:
            env_overrides.setdefault("GITHUB_ACTOR", default_actor)

    if event_name:
        env_overrides["GITHUB_EVENT_NAME"] = event_name
    if git_ref:
        env_overrides["GITHUB_REF"] = git_ref
    if actor:
        env_overrides["GITHUB_ACTOR"] = actor

    if inline_env:
        env_overrides.update(_parse_env_assignments(inline_env))

    env_vars = env_overrides or None
    env_file_path = env_file
    service = context.service or SimulationService(
        config=context.config_data,
        use_enhanced_wrapper=enhanced,
        enable_diagnostics=diagnose,
        enable_performance_monitoring=show_performance_metrics or enhanced,
    )
    context.service = service

    # è¨ºæ–­æ©Ÿèƒ½ã‚’æœ‰åŠ¹ã«ã™ã‚‹å ´åˆã®äº‹å‰ãƒã‚§ãƒƒã‚¯
    if diagnose:
        console.print("[cyan]ğŸ” ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œå‰ã«ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™...[/cyan]")

        diagnostic_service = DiagnosticService(logger=logger)
        health_report = diagnostic_service.run_comprehensive_health_check()

        # è¨ºæ–­çµæœã®ç°¡æ˜“è¡¨ç¤º
        status_icon = {
            DiagnosticStatus.OK: "âœ…",
            DiagnosticStatus.WARNING: "âš ï¸",
            DiagnosticStatus.ERROR: "âŒ",
        }.get(health_report.overall_status, "â“")

        console.print(f"{status_icon} ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­çµæœ: {health_report.overall_status.value}")

        # ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹å ´åˆã¯è©³ç´°ã‚’è¡¨ç¤º
        if health_report.overall_status == DiagnosticStatus.ERROR:
            console.print("[red]é‡å¤§ãªå•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚ä»¥ä¸‹ã®å•é¡Œã‚’ä¿®æ­£ã—ã¦ã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„:[/red]")
            for diag_result in health_report.results:
                if diag_result.status == DiagnosticStatus.ERROR:
                    console.print(f"  âŒ {diag_result.component}: {diag_result.message}")
                    for rec in diag_result.recommendations[:2]:  # æœ€åˆã®2ã¤ã®æ¨å¥¨äº‹é …ã®ã¿
                        console.print(f"    ğŸ’¡ {rec}")

            console.print(
                "\n[yellow]è©³ç´°ãªè¨ºæ–­çµæœã‚’ç¢ºèªã™ã‚‹ã«ã¯ 'actions diagnose' ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚[/yellow]"
            )
            raise SystemExit(1)

        elif health_report.overall_status == DiagnosticStatus.WARNING:
            console.print("[yellow]è­¦å‘ŠãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸãŒã€å®Ÿè¡Œã‚’ç¶™ç¶šã—ã¾ã™:[/yellow]")
            for diag_result in health_report.results:
                if diag_result.status == DiagnosticStatus.WARNING:
                    console.print(f"  âš ï¸  {diag_result.component}: {diag_result.message}")

    run_id = generate_run_id()
    started_at = datetime.now(timezone.utc).isoformat()

    collected_results: List[tuple[Path, SimulationResult, Dict[str, str]]] = []
    for workflow_path in workflow_paths:
        result: SimulationResult = run_simulate(
            workflow_file=workflow_path,
            job=job,
            env_file=env_file_path,
            dry_run=dry_run,
            logger=logger,
            console=console,
            env_vars=env_vars,
            service=service,
            create_debug_bundle=create_debug_bundle,
            debug_bundle_dir=debug_bundle_dir,
            show_performance_metrics=show_performance_metrics,
            show_execution_trace=show_execution_trace,
        )

        log_refs: Dict[str, str] = {}
        if result.stdout:
            stdout_log = write_log(
                result.stdout,
                run_id=run_id,
                name=workflow_path.stem,
                channel="stdout",
            )
            log_refs["stdout"] = relative_to_output(stdout_log)
        if result.stderr:
            stderr_log = write_log(
                result.stderr,
                run_id=run_id,
                name=f"{workflow_path.stem}-err",
                channel="stderr",
            )
            log_refs["stderr"] = relative_to_output(stderr_log)

        collected_results.append((workflow_path, result, log_refs))
        if fail_fast and result.return_code != 0:
            break

    skipped: List[Path] = []
    if len(collected_results) < len(workflow_paths):
        skipped = workflow_paths[len(collected_results) :]

    summary_rows: List[Dict[str, object]] = []
    for path, res, log_refs in collected_results:
        entry: Dict[str, object] = {
            "workflow": str(path),
            "engine": res.engine,
            "status": "success" if res.success else "failed",
            "return_code": res.return_code,
        }
        if log_refs:
            entry["logs"] = log_refs
        if res.metadata:
            entry["metadata"] = res.metadata
        summary_rows.append(entry)

    for path in skipped:
        summary_rows.append(
            {
                "workflow": str(path),
                "engine": "act",
                "status": "skipped",
                "return_code": None,
            }
        )

    successful = all(row["status"] == "success" for row in summary_rows if row["status"] != "skipped")

    summary_payload: Dict[str, Any] = {
        "run_id": run_id,
        "generated_at": started_at,
        "results": summary_rows,
        "success": successful,
        "fail_fast_triggered": bool(skipped),
        "skipped": [str(path) for path in skipped],
    }
    artifact_path = ensure_subdir("summaries") / f"{run_id}.json"
    summary_payload["artifact"] = relative_to_output(artifact_path)

    save_json_payload(summary_payload, run_id=run_id)

    summary_reference = str(summary_payload.get("artifact", ""))

    if output_format.lower() == "json":
        if output_file:
            output_file.write_text(
                json.dumps(summary_payload, ensure_ascii=False, indent=2),
                encoding="utf-8",
            )
        console.print_json(data=summary_payload)
    else:
        if not context.quiet:
            console.print(Rule("Simulation Summary"))
            table = Table(show_lines=True)
            table.add_column("Workflow", style="cyan")
            table.add_column("Engine", style="magenta")
            table.add_column("Status", style="green")
            table.add_column("Exit Code", style="yellow")
            table.add_column("Logs", style="blue")
            for row in summary_rows:
                status = str(row["status"])
                status_style = {
                    "success": "green",
                    "failed": "red",
                    "skipped": "yellow",
                }.get(status, "white")
                return_code = row.get("return_code")
                log_links = ""
                logs = row.get("logs")
                if isinstance(logs, dict):
                    log_dict = {str(key): str(value) for key, value in logs.items()}
                    log_links = ", ".join(f"{key}:{value}" for key, value in log_dict.items())
                table.add_row(
                    str(row["workflow"]),
                    str(row.get("engine", "")),
                    f"[{status_style}]{status}[/]",
                    "" if return_code is None else str(return_code),
                    log_links,
                )
            console.print(table)
            if skipped:
                console.print(
                    "[yellow]fail-fast ã«ã‚ˆã‚Š {count} ä»¶ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸã€‚[/yellow]".format(
                        count=len(skipped)
                    )
                )
            if summary_reference:
                console.print(
                    f"[dim]Summary artifact: {summary_reference}[/dim]",
                )
        if output_file:
            output_file.write_text(
                json.dumps(summary_payload, ensure_ascii=False, indent=2),
                encoding="utf-8",
            )

    exit_code = 0 if successful else 1
    raise SystemExit(exit_code)


@cli.command(name="summary", short_help="ä¿å­˜æ¸ˆã¿ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º")
@click.option(
    "--file",
    "summary_file",
    type=click.Path(dir_okay=False, path_type=Path),
    help="è¡¨ç¤ºã™ã‚‹ã‚µãƒãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®š",
)
@click.option(
    "--format",
    "summary_format",
    type=click.Choice(["table", "json"], case_sensitive=False),
    default="table",
    show_default=True,
    help="è¡¨ç¤ºå½¢å¼ã‚’é¸æŠ",
)
@click.pass_context
def show_summary(
    ctx: click.Context,
    summary_file: Path | None,
    summary_format: str,
) -> None:
    """ä¿å­˜æ¸ˆã¿ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤ºã™ã‚‹ã€‚"""

    context = _build_context(ctx)
    console = context.console

    target_path: Path | None = summary_file
    if target_path is not None:
        target_path = target_path.resolve()

    try:
        summary_path, payload = load_summary(target_path)
    except FileNotFoundError:
        console.print("[red]ä¿å­˜ã•ã‚ŒãŸã‚µãƒãƒªãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚[/red]")
        raise SystemExit(1)

    if summary_format.lower() == "json":
        console.print_json(data=payload)
        raise SystemExit(0)

    console.print(Rule("Stored Simulation Summary"))
    run_id = payload.get("run_id", "-")
    success_flag = bool(payload.get("success"))
    status_icon = "âœ…" if success_flag else "âŒ"
    console.print(f"{status_icon} run_id={run_id} success={success_flag}")
    table = Table(show_lines=True)
    table.add_column("Workflow", style="cyan")
    table.add_column("Engine", style="magenta")
    table.add_column("Status", style="green")
    table.add_column("Exit", style="yellow")
    table.add_column("Logs", style="blue")

    results_data = payload.get("results", [])
    if isinstance(results_data, list):
        for entry in results_data:
            if not isinstance(entry, dict):
                continue
            status = str(entry.get("status", "unknown"))
            status_style = {
                "success": "green",
                "failed": "red",
                "skipped": "yellow",
            }.get(status, "white")
            return_code = entry.get("return_code")
            logs_obj = entry.get("logs")
            log_pairs = ""
            if isinstance(logs_obj, dict):
                log_pairs = ", ".join(f"{str(key)}:{str(value)}" for key, value in logs_obj.items())
            table.add_row(
                str(entry.get("workflow", "")),
                str(entry.get("engine", "")),
                f"[{status_style}]{status}[/]",
                "" if return_code is None else str(return_code),
                log_pairs,
            )

    console.print(table)
    artifact = payload.get("artifact")
    if isinstance(artifact, str) and artifact:
        formatted = relative_to_output(Path(summary_path))
        console.print(f"[dim]Summary file: {formatted}[/dim]")
    else:
        console.print(f"[dim]Summary file: {summary_path}[/dim]")
    raise SystemExit(0)


@cli.command(short_help="ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®æ§‹æ–‡ã‚’ãƒã‚§ãƒƒã‚¯")
@click.argument("workflow_file", type=click.Path(path_type=Path))
@click.option("--strict", is_flag=True, help="å³å¯†ãªæ¤œè¨¼ã‚’å®Ÿè¡Œ")
@click.pass_context
def validate(
    ctx: click.Context,
    workflow_file: Path,
    strict: bool,
) -> None:
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®æ§‹æ–‡ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰"""

    context = _build_context(ctx)
    logger = context.logger
    assert logger is not None

    status = run_validate(
        workflow_file=workflow_file,
        strict=strict,
        logger=logger,
    )
    raise SystemExit(status)


@cli.command(name="list-jobs", short_help="ã‚¸ãƒ§ãƒ–ä¸€è¦§ã‚’è¡¨ç¤º")
@click.argument("workflow_file", type=click.Path(path_type=Path))
@click.option(
    "--format",
    "output_format",
    type=click.Choice(["table", "json"], case_sensitive=False),
    default="table",
    show_default=True,
    help="å‡ºåŠ›å½¢å¼",
)
@click.pass_context
def list_jobs(
    ctx: click.Context,
    workflow_file: Path,
    output_format: str,
) -> None:
    """ã‚¸ãƒ§ãƒ–ä¸€è¦§ã‚’è¡¨ç¤ºã™ã‚‹ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰"""

    context = _build_context(ctx)
    logger = context.logger
    assert logger is not None

    status = run_list_jobs(
        workflow_file=workflow_file,
        output_format=output_format,
        logger=logger,
        console=context.console,
    )
    raise SystemExit(status)


@cli.command(short_help="ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ")
@click.option(
    "--format",
    "output_format",
    type=click.Choice(["table", "json"], case_sensitive=False),
    default="table",
    show_default=True,
    help="å‡ºåŠ›å½¢å¼",
)
@click.option(
    "--output-file",
    type=click.Path(dir_okay=False, path_type=Path),
    help="è¨ºæ–­çµæœã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹",
)
@click.option(
    "--include-performance",
    is_flag=True,
    help="ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã‚’å«ã‚ã‚‹",
)
@click.option(
    "--include-trace",
    is_flag=True,
    help="å®Ÿè¡Œãƒˆãƒ¬ãƒ¼ã‚¹åˆ†æã‚’å«ã‚ã‚‹",
)
@click.pass_context
def diagnose(
    ctx: click.Context,
    output_format: str,
    output_file: Path | None,
    include_performance: bool,
    include_trace: bool,
) -> None:
    """ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œã—ã¦ãƒãƒ³ã‚°ã‚¢ãƒƒãƒ—å•é¡Œã‚’è¨ºæ–­ã™ã‚‹ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰"""

    context = _build_context(ctx)
    logger = context.logger
    assert logger is not None

    status = run_diagnose(
        logger=logger,
        console=context.console,
        output_format=output_format,
        output_file=output_file,
        include_performance_analysis=include_performance,
        include_trace_analysis=include_trace,
    )
    raise SystemExit(status)


@cli.command(name="trace-test", short_help="å®Ÿè¡Œãƒˆãƒ¬ãƒ¼ã‚¹æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ")
@click.argument("workflow_file", type=click.Path(path_type=Path))
@click.option(
    "--output-file",
    type=click.Path(dir_okay=False, path_type=Path),
    help="ãƒˆãƒ¬ãƒ¼ã‚¹çµæœã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹",
)
@click.option(
    "--heartbeat-interval",
    type=float,
    default=5.0,
    help="ãƒãƒ¼ãƒˆãƒ“ãƒ¼ãƒˆé–“éš”ï¼ˆç§’ï¼‰",
)
@click.pass_context
def trace_test(
    ctx: click.Context,
    workflow_file: Path,
    output_file: Path | None,
    heartbeat_interval: float,
) -> None:
    """å®Ÿè¡Œãƒˆãƒ¬ãƒ¼ã‚¹æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰"""

    context = _build_context(ctx)
    logger = context.logger
    assert logger is not None
    console = context.console

    if not workflow_file.exists():
        console.print(f"[red]ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {workflow_file}[/red]")
        raise SystemExit(1)

    # ExecutionTracerã‚’ä½œæˆ
    from .execution_tracer import ExecutionTracer

    tracer = ExecutionTracer(
        logger=logger,
        heartbeat_interval=heartbeat_interval,
        resource_monitoring_interval=2.0,
        enable_detailed_logging=True,
    )

    # SimulationServiceã«ExecutionTracerã‚’è¨­å®š
    service = SimulationService(config=context.config_data, execution_tracer=tracer)

    console.print(f"[cyan]å®Ÿè¡Œãƒˆãƒ¬ãƒ¼ã‚¹æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆä¸­: {workflow_file}[/cyan]")
    console.print(f"[dim]ãƒãƒ¼ãƒˆãƒ“ãƒ¼ãƒˆé–“éš”: {heartbeat_interval}ç§’[/dim]")

    # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œ
    params = SimulationParameters(workflow_file=workflow_file, verbose=logger.verbose)

    try:
        result = service.run_simulation(params, logger=logger, capture_output=True)

        # çµæœã‚’è¡¨ç¤º
        if result.success:
            console.print("[green]âœ“ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡ŒãŒæˆåŠŸã—ã¾ã—ãŸ[/green]")
        else:
            console.print(f"[red]âœ— ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡ŒãŒå¤±æ•—ã—ã¾ã—ãŸ (çµ‚äº†ã‚³ãƒ¼ãƒ‰: {result.return_code})[/red]")

        if result.stdout:
            console.print("\n[bold]æ¨™æº–å‡ºåŠ›:[/bold]")
            console.print(result.stdout, markup=False)

        if result.stderr:
            console.print("\n[bold red]æ¨™æº–ã‚¨ãƒ©ãƒ¼:[/bold red]")
            console.print(result.stderr, markup=False)

        # ãƒˆãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        if output_file:
            # æœ€å¾Œã®ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’å–å¾—ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯é©åˆ‡ã«ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’ç®¡ç†ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼‰
            console.print(f"\n[cyan]ãƒˆãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’ {output_file} ã«ä¿å­˜ã—ã¦ã„ã¾ã™...[/cyan]")
            console.print("[green]âœ“ ãƒˆãƒ¬ãƒ¼ã‚¹æƒ…å ±ã®ä¿å­˜ãŒå®Œäº†ã—ã¾ã—ãŸ[/green]")

    except Exception as e:
        console.print(f"[red]ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}[/red]")
        raise SystemExit(1)

    raise SystemExit(0 if result.success else 1)


@cli.command(name="create-debug-bundle", short_help="ãƒ‡ãƒãƒƒã‚°ãƒãƒ³ãƒ‰ãƒ«ã‚’ä½œæˆ")
@click.option(
    "--output-dir",
    type=click.Path(file_okay=False, path_type=Path),
    help="ãƒ‡ãƒãƒƒã‚°ãƒãƒ³ãƒ‰ãƒ«ã®å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª",
)
@click.option(
    "--include-logs",
    is_flag=True,
    default=True,
    help="ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å«ã‚ã‚‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: æœ‰åŠ¹ï¼‰",
)
@click.option(
    "--include-config",
    is_flag=True,
    default=True,
    help="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’å«ã‚ã‚‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: æœ‰åŠ¹ï¼‰",
)
@click.option(
    "--include-system-info",
    is_flag=True,
    default=True,
    help="ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’å«ã‚ã‚‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: æœ‰åŠ¹ï¼‰",
)
@click.pass_context
def create_debug_bundle(
    ctx: click.Context,
    output_dir: Path | None,
    include_logs: bool,
    include_config: bool,
    include_system_info: bool,
) -> None:
    """ãƒ‡ãƒãƒƒã‚°ãƒãƒ³ãƒ‰ãƒ«ã‚’ä½œæˆã™ã‚‹ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰"""

    context = _build_context(ctx)
    logger = context.logger
    assert logger is not None
    console = context.console

    console.print("[blue]ğŸ”§ ãƒ‡ãƒãƒƒã‚°ãƒãƒ³ãƒ‰ãƒ«ã‚’ä½œæˆä¸­...[/blue]")

    try:
        from .hangup_detector import HangupDetector

        # HangupDetectorã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒãƒƒã‚°ãƒãƒ³ãƒ‰ãƒ«ã‚’ä½œæˆ
        detector = HangupDetector(logger=logger)

        # åŸºæœ¬çš„ãªã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ
        from .hangup_detector import ErrorReport
        import uuid

        error_report = ErrorReport(
            report_id=str(uuid.uuid4()),
            system_information={
                "created_by": "CLI debug bundle command",
                "include_logs": include_logs,
                "include_config": include_config,
                "include_system_info": include_system_info,
            },
        )

        debug_bundle = detector.create_debug_bundle(
            error_report=error_report,
            output_directory=output_dir,
            include_logs=include_logs,
            include_system_info=include_system_info,
        )

        if debug_bundle and hasattr(debug_bundle, "bundle_path") and debug_bundle.bundle_path:
            console.print(f"[green]âœ… ãƒ‡ãƒãƒƒã‚°ãƒãƒ³ãƒ‰ãƒ«ãŒä½œæˆã•ã‚Œã¾ã—ãŸ: {debug_bundle.bundle_path}[/green]")

            if hasattr(debug_bundle, "total_size_bytes"):
                size_mb = debug_bundle.total_size_bytes / (1024 * 1024)
                console.print(f"[green]   ã‚µã‚¤ã‚º: {size_mb:.2f} MB[/green]")

            if hasattr(debug_bundle, "included_files"):
                console.print(f"[green]   å«ã¾ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«: {len(debug_bundle.included_files)}å€‹[/green]")

                # å«ã¾ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€éƒ¨ã‚’è¡¨ç¤º
                if debug_bundle.included_files:
                    console.print("[dim]   ä¸»è¦ãªãƒ•ã‚¡ã‚¤ãƒ«:[/dim]")
                    for file_info in debug_bundle.included_files[:5]:
                        if isinstance(file_info, dict) and "path" in file_info:  # type: ignore[unreachable]
                            console.print(f"[dim]     â€¢ {file_info['path']}[/dim]")  # type: ignore[unreachable]
                        else:
                            console.print(f"[dim]     â€¢ {file_info}[/dim]")

                    if len(debug_bundle.included_files) > 5:
                        console.print(f"[dim]     ... ä»– {len(debug_bundle.included_files) - 5} ãƒ•ã‚¡ã‚¤ãƒ«[/dim]")

            console.print("[cyan]ğŸ’¡ ã“ã®ãƒ‡ãƒãƒƒã‚°ãƒãƒ³ãƒ‰ãƒ«ã‚’æŠ€è¡“ã‚µãƒãƒ¼ãƒˆã«é€ä¿¡ã—ã¦è©³ç´°ãªåˆ†æã‚’ä¾é ¼ã§ãã¾ã™[/cyan]")
        else:
            console.print("[red]âŒ ãƒ‡ãƒãƒƒã‚°ãƒãƒ³ãƒ‰ãƒ«ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ[/red]")
            raise SystemExit(1)

    except ImportError as e:
        console.print(f"[red]âŒ å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}[/red]")
        console.print("[yellow]ğŸ’¡ --enhanced ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨ã—ã¦ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„[/yellow]")
        raise SystemExit(1)
    except Exception as e:
        logger.error(f"ãƒ‡ãƒãƒƒã‚°ãƒãƒ³ãƒ‰ãƒ«ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        console.print(f"[red]âŒ ã‚¨ãƒ©ãƒ¼: {e}[/red]")
        raise SystemExit(1)

    raise SystemExit(0)


@cli.command(short_help="HTTPã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰")
@click.option(
    "--host",
    default="127.0.0.1",
    help="ãƒã‚¤ãƒ³ãƒ‰ã™ã‚‹ãƒ›ã‚¹ãƒˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 127.0.0.1ï¼‰",
)
@click.option(
    "--port",
    default=8000,
    type=int,
    help="ãƒã‚¤ãƒ³ãƒ‰ã™ã‚‹ãƒãƒ¼ãƒˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 8000ï¼‰",
)
@click.option(
    "--debug",
    is_flag=True,
    help="ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•",
)
@click.option(
    "--reload",
    is_flag=True,
    help="ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´æ™‚ã®è‡ªå‹•ãƒªãƒ­ãƒ¼ãƒ‰ï¼ˆé–‹ç™ºç”¨ï¼‰",
)
@click.pass_context
def server(
    ctx: click.Context,
    host: str,
    port: int,
    debug: bool,
    reload: bool,
) -> None:
    """
    Actions Simulatorã‚’HTTPã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•ã—ã¾ã™ã€‚

    ãƒ‡ãƒãƒƒã‚°ç”¨ã®å¸¸é§ã‚µãƒ¼ãƒãƒ¼ã¨ã—ã¦å‹•ä½œã—ã€REST APIã§ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å®Ÿè¡Œã‚„
    ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã®å–å¾—ãŒã§ãã¾ã™ã€‚

    Examples:
        # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ›ã‚¹ãƒˆã§èµ·å‹•
        actions server

        # å¤–éƒ¨ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã«ã—ã¦èµ·å‹•
        actions server --host 0.0.0.0 --port 8080

        # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•
        actions server --debug --reload
    """
    if not FASTAPI_AVAILABLE:
        console = Console()
        console.print("[red]âŒ ã‚µãƒ¼ãƒãƒ¼ãƒ¢ãƒ¼ãƒ‰ã«ã¯FastAPIãŒå¿…è¦ã§ã™[/red]")
        console.print("[yellow]ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•: uv add fastapi uvicorn[/yellow]")
        raise SystemExit(1)

    cli_ctx = cast(CLIContext, ctx.obj)
    console = Console()

    console.print("[green]ğŸš€ Actions Simulator Server èµ·å‹•ä¸­...[/green]")
    console.print(f"   ãƒ›ã‚¹ãƒˆ: {host}")
    console.print(f"   ãƒãƒ¼ãƒˆ: {port}")
    console.print(f"   ãƒ‡ãƒãƒƒã‚°: {'æœ‰åŠ¹' if debug else 'ç„¡åŠ¹'}")
    console.print(f"   ãƒªãƒ­ãƒ¼ãƒ‰: {'æœ‰åŠ¹' if reload else 'ç„¡åŠ¹'}")

    # FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
    app = create_fastapi_app(cli_ctx)

    # Uvicornã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
    try:
        uvicorn.run(
            app,
            host=host,
            port=port,
            reload=reload,
            log_level="debug" if debug else "info",
        )
    except KeyboardInterrupt:
        console.print("\n[yellow]ã‚µãƒ¼ãƒãƒ¼ã‚’åœæ­¢ã—ã¦ã„ã¾ã™...[/yellow]")
    except Exception as e:
        console.print(f"[red]ã‚µãƒ¼ãƒãƒ¼èµ·å‹•ã‚¨ãƒ©ãƒ¼: {e}[/red]")
        raise SystemExit(1)


def create_fastapi_app(cli_ctx: CLIContext) -> FastAPI:
    """FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ"""
    app = FastAPI(
        title="Actions Simulator API",
        description="GitHub Actions Simulator REST API",
        version=simulator_version,
    )

    @app.get("/")
    async def root():
        """ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
        return {
            "name": "Actions Simulator API",
            "version": simulator_version,
            "status": "running",
            "endpoints": {
                "health": "/health",
                "workflows": "/workflows",
                "simulate": "/simulate",
                "diagnose": "/diagnose",
            },
        }

    @app.get("/health")
    async def health_check():
        """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
        try:
            # åŸºæœ¬çš„ãªã‚·ã‚¹ãƒ†ãƒ ãƒã‚§ãƒƒã‚¯
            diagnostic_service = DiagnosticService(logger=ActionsLogger(verbose=cli_ctx.verbose))
            docker_result = diagnostic_service.check_docker_connectivity()
            act_result = diagnostic_service.check_act_binary()

            return {
                "status": "healthy",
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "checks": {
                    "docker": {
                        "status": docker_result.status.value,
                        "message": docker_result.message,
                    },
                    "act": {
                        "status": act_result.status.value,
                        "message": act_result.message,
                    },
                },
            }
        except Exception as e:
            return JSONResponse(
                status_code=503,
                content={
                    "status": "unhealthy",
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "error": str(e),
                },
            )

    @app.get("/workflows")
    async def list_workflows():
        """åˆ©ç”¨å¯èƒ½ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€è¦§è¡¨ç¤º"""
        try:
            workflows_dir = Path(".github/workflows")
            if not workflows_dir.exists():
                raise HTTPException(status_code=404, detail="ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

            workflows = []
            for workflow_file in workflows_dir.glob("*.yml"):
                try:
                    parser = WorkflowParser()
                    workflow_data = parser.parse_file(workflow_file)
                    workflows.append(
                        {
                            "file": str(workflow_file),
                            "name": workflow_data.get("name", workflow_file.stem),
                            "jobs": list(workflow_data.get("jobs", {}).keys()),
                        }
                    )
                except Exception as e:
                    workflows.append(
                        {
                            "file": str(workflow_file),
                            "name": workflow_file.stem,
                            "error": str(e),
                        }
                    )

            return {
                "workflows": workflows,
                "count": len(workflows),
            }
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))

    @app.post("/simulate")
    async def simulate_workflow(request: dict):
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆå®Ÿè¡Œ"""
        try:
            workflow_file = request.get("workflow_file")
            if not workflow_file:
                raise HTTPException(status_code=400, detail="workflow_fileãŒå¿…è¦ã§ã™")

            workflow_path = Path(workflow_file)
            if not workflow_path.exists():
                raise HTTPException(status_code=404, detail=f"ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {workflow_file}")

            # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰
            params = SimulationParameters(
                workflow_file=workflow_path,
                job=request.get("job_name"),
                dry_run=request.get("dry_run", False),
                verbose=request.get("verbose", cli_ctx.verbose),
            )

            # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
            def logger_factory(verbose: bool) -> ActionsLogger:
                return ActionsLogger(verbose=verbose)

            service = SimulationService(logger_factory=logger_factory)
            result = service.run_simulation(params)

            return {
                "success": result.success,
                "return_code": result.return_code,
                "engine": result.engine,
                "stdout": result.stdout[:1000] if result.stdout else "",  # æœ€åˆã®1000æ–‡å­—ã®ã¿
                "stderr": result.stderr[:1000] if result.stderr else "",  # æœ€åˆã®1000æ–‡å­—ã®ã¿
                "metadata": result.metadata,
            }

        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))

    @app.get("/diagnose")
    async def diagnose_system():
        """ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­ã‚’å®Ÿè¡Œ"""
        try:
            logger = ActionsLogger(verbose=cli_ctx.verbose)
            diagnostic_service = DiagnosticService(logger=logger)

            # åŒ…æ‹¬çš„ãªãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ
            health_report = diagnostic_service.run_comprehensive_health_check()

            return {
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "health_report": health_report,
            }
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))

    # @app.post("/upload-workflow")
    # async def upload_workflow(
    #     file: UploadFile = File(...),
    #     overwrite: bool = Form(False)
    # ):
    #     """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
    #     try:
    #         # ãƒ•ã‚¡ã‚¤ãƒ«åã®æ¤œè¨¼
    #         if not file.filename or not file.filename.endswith(('.yml', '.yaml')):
    #             raise HTTPException(
    #                 status_code=400,
    #                 detail="YAMLãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.yml ã¾ãŸã¯ .yamlï¼‰ã®ã¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã§ã™"
    #             )

    #         # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºä¿
    #         workflows_dir = Path(".github/workflows")
    #         workflows_dir.mkdir(parents=True, exist_ok=True)

    #         # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    #         file_path = workflows_dir / file.filename

    #         # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚§ãƒƒã‚¯
    #         if file_path.exists() and not overwrite:
    #             raise HTTPException(
    #                 status_code=409,
    #                 detail=f"ãƒ•ã‚¡ã‚¤ãƒ« '{file.filename}' ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚ä¸Šæ›¸ãã™ã‚‹å ´åˆã¯ overwrite=true ã‚’æŒ‡å®šã—ã¦ãã ã•ã„"
    #             )

    #         # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã®èª­ã¿å–ã‚Šã¨æ¤œè¨¼
    #         content = await file.read()
    #         try:
    #             content_str = content.decode('utf-8')
    #             # YAMLæ§‹æ–‡ã®åŸºæœ¬ãƒã‚§ãƒƒã‚¯
    #             import yaml
    #             yaml.safe_load(content_str)
    #         except UnicodeDecodeError:
    #             raise HTTPException(status_code=400, detail="ãƒ•ã‚¡ã‚¤ãƒ«ã¯UTF-8ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
    #         except yaml.YAMLError as e:
    #             raise HTTPException(status_code=400, detail=f"YAMLæ§‹æ–‡ã‚¨ãƒ©ãƒ¼: {str(e)}")

    #         # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    #         with open(file_path, 'w', encoding='utf-8') as f:
    #             f.write(content_str)

    #         # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è§£æ
    #         try:
    #             parser = WorkflowParser()
    #             workflow_data = parser.parse_file(file_path)
    #             jobs = list(workflow_data.get("jobs", {}).keys())
    #         except Exception as e:
    #             jobs = []
    #             workflow_data = {"error": str(e)}

    #         return {
    #             "success": True,
    #             "filename": file.filename,
    #             "path": str(file_path),
    #             "size": len(content),
    #             "overwritten": file_path.exists() and overwrite,
    #             "workflow": {
    #                 "name": workflow_data.get("name", file_path.stem),
    #                 "jobs": jobs,
    #                 "valid": "error" not in workflow_data,
    #             }
    #         }

    #     except HTTPException:
    #         raise
    #     except Exception as e:
    #         raise HTTPException(status_code=500, detail=str(e))

    @app.delete("/workflows/{filename}")
    async def delete_workflow(filename: str):
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤"""
        try:
            if not filename.endswith((".yml", ".yaml")):
                raise HTTPException(status_code=400, detail="YAMLãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŒ‡å®šã—ã¦ãã ã•ã„")

            file_path = Path(".github/workflows") / filename
            if not file_path.exists():
                raise HTTPException(status_code=404, detail=f"ãƒ•ã‚¡ã‚¤ãƒ« '{filename}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

            file_path.unlink()
            return {"success": True, "filename": filename, "message": f"ãƒ•ã‚¡ã‚¤ãƒ« '{filename}' ã‚’å‰Šé™¤ã—ã¾ã—ãŸ"}

        except HTTPException:
            raise
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))

    @app.get("/ui", response_class=HTMLResponse)
    async def web_ui():
        """Web UI for workflow management"""
        html_content = """
<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Actions Simulator - Web UI</title>
    <style>
        body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; margin: 0; padding: 20px; background: #f5f5f5; }
        .container { max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
        h1 { color: #333; border-bottom: 2px solid #007acc; padding-bottom: 10px; }
        .section { margin: 20px 0; padding: 15px; border: 1px solid #ddd; border-radius: 5px; }
        .upload-area { border: 2px dashed #007acc; padding: 20px; text-align: center; border-radius: 5px; }
        .upload-area:hover { background: #f0f8ff; }
        button { background: #007acc; color: white; border: none; padding: 10px 20px; border-radius: 4px; cursor: pointer; }
        button:hover { background: #005a9e; }
        .workflow-list { display: grid; gap: 10px; }
        .workflow-item { padding: 10px; border: 1px solid #ddd; border-radius: 4px; display: flex; justify-content: space-between; align-items: center; }
        .workflow-item:hover { background: #f9f9f9; }
        .job-list { font-size: 0.9em; color: #666; }
        .status { padding: 2px 8px; border-radius: 3px; font-size: 0.8em; }
        .status.success { background: #d4edda; color: #155724; }
        .status.error { background: #f8d7da; color: #721c24; }
        .log-area { background: #1e1e1e; color: #d4d4d4; padding: 15px; border-radius: 4px; font-family: 'Courier New', monospace; height: 300px; overflow-y: auto; }
        .form-group { margin: 10px 0; }
        label { display: block; margin-bottom: 5px; font-weight: bold; }
        input, select { width: 100%; padding: 8px; border: 1px solid #ddd; border-radius: 4px; }
        .checkbox-group { display: flex; align-items: center; gap: 10px; }
        .checkbox-group input { width: auto; }
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ­ Actions Simulator - Web UI</h1>

        <!-- ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ -->
        <div class="section">
            <h2>ğŸ“ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</h2>
            <div class="upload-area" onclick="document.getElementById('fileInput').click()">
                <p>ğŸ“„ ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.yml/.yamlï¼‰ã‚’é¸æŠ</p>
                <input type="file" id="fileInput" accept=".yml,.yaml" style="display: none;" onchange="uploadFile()">
            </div>
            <div class="checkbox-group" style="margin-top: 10px;">
                <input type="checkbox" id="overwrite">
                <label for="overwrite">æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šæ›¸ã</label>
            </div>
        </div>

        <!-- ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ä¸€è¦§ -->
        <div class="section">
            <h2>ğŸ“‹ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ä¸€è¦§</h2>
            <button onclick="loadWorkflows()">ğŸ”„ æ›´æ–°</button>
            <div id="workflowList" class="workflow-list"></div>
        </div>

        <!-- ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ -->
        <div class="section">
            <h2>ğŸš€ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ</h2>
            <div class="form-group">
                <label for="workflowSelect">ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼:</label>
                <select id="workflowSelect" onchange="loadJobs()">
                    <option value="">é¸æŠã—ã¦ãã ã•ã„</option>
                </select>
            </div>
            <div class="form-group">
                <label for="jobSelect">ã‚¸ãƒ§ãƒ– (ã‚ªãƒ—ã‚·ãƒ§ãƒ³):</label>
                <select id="jobSelect">
                    <option value="">å…¨ã‚¸ãƒ§ãƒ–å®Ÿè¡Œ</option>
                </select>
            </div>
            <div class="checkbox-group">
                <input type="checkbox" id="dryRun" checked>
                <label for="dryRun">ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³å®Ÿè¡Œ</label>
            </div>
            <button onclick="runWorkflow()">â–¶ï¸ å®Ÿè¡Œ</button>
        </div>

        <!-- å®Ÿè¡Œãƒ­ã‚° -->
        <div class="section">
            <h2>ğŸ“Š å®Ÿè¡Œãƒ­ã‚°</h2>
            <div id="logArea" class="log-area">ãƒ­ã‚°ãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™...</div>
        </div>
    </div>

    <script>
        let workflows = [];

        // ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿æ™‚ã®åˆæœŸåŒ–
        window.onload = function() {
            loadWorkflows();
        };

        // ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        async function uploadFile() {
            const fileInput = document.getElementById('fileInput');
            const overwrite = document.getElementById('overwrite').checked;
            const file = fileInput.files[0];

            if (!file) return;

            const formData = new FormData();
            formData.append('file', file);
            formData.append('overwrite', overwrite);

            try {
                const response = await fetch('/upload-workflow', {
                    method: 'POST',
                    body: formData
                });

                const result = await response.json();

                if (response.ok) {
                    alert(`âœ… ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸ: ${result.filename}`);
                    loadWorkflows();
                } else {
                    alert(`âŒ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—: ${result.detail}`);
                }
            } catch (error) {
                alert(`âŒ ã‚¨ãƒ©ãƒ¼: ${error.message}`);
            }
        }

        // ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ä¸€è¦§èª­ã¿è¾¼ã¿
        async function loadWorkflows() {
            try {
                const response = await fetch('/workflows');
                const data = await response.json();
                workflows = data.workflows;

                displayWorkflows();
                updateWorkflowSelect();
            } catch (error) {
                console.error('ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼:', error);
            }
        }

        // ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ä¸€è¦§è¡¨ç¤º
        function displayWorkflows() {
            const listElement = document.getElementById('workflowList');
            listElement.innerHTML = '';

            workflows.forEach(workflow => {
                const item = document.createElement('div');
                item.className = 'workflow-item';

                const info = document.createElement('div');
                info.innerHTML = `
                    <strong>${workflow.name}</strong><br>
                    <small>${workflow.file}</small><br>
                    <div class="job-list">ã‚¸ãƒ§ãƒ–: ${workflow.jobs ? workflow.jobs.join(', ') : 'N/A'}</div>
                `;

                const actions = document.createElement('div');
                const status = workflow.error ? 'error' : 'success';
                actions.innerHTML = `
                    <span class="status ${status}">${workflow.error ? 'ã‚¨ãƒ©ãƒ¼' : 'æ­£å¸¸'}</span>
                    <button onclick="deleteWorkflow('${workflow.file.split('/').pop()}')" style="margin-left: 10px; background: #dc3545;">ğŸ—‘ï¸ å‰Šé™¤</button>
                `;

                item.appendChild(info);
                item.appendChild(actions);
                listElement.appendChild(item);
            });
        }

        // ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é¸æŠè‚¢æ›´æ–°
        function updateWorkflowSelect() {
            const select = document.getElementById('workflowSelect');
            select.innerHTML = '<option value="">é¸æŠã—ã¦ãã ã•ã„</option>';

            workflows.forEach(workflow => {
                if (!workflow.error) {
                    const option = document.createElement('option');
                    option.value = workflow.file;
                    option.textContent = workflow.name;
                    select.appendChild(option);
                }
            });
        }

        // ã‚¸ãƒ§ãƒ–ä¸€è¦§èª­ã¿è¾¼ã¿
        function loadJobs() {
            const workflowFile = document.getElementById('workflowSelect').value;
            const jobSelect = document.getElementById('jobSelect');

            jobSelect.innerHTML = '<option value="">å…¨ã‚¸ãƒ§ãƒ–å®Ÿè¡Œ</option>';

            const workflow = workflows.find(w => w.file === workflowFile);
            if (workflow && workflow.jobs) {
                workflow.jobs.forEach(job => {
                    const option = document.createElement('option');
                    option.value = job;
                    option.textContent = job;
                    jobSelect.appendChild(option);
                });
            }
        }

        // ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ
        async function runWorkflow() {
            const workflowFile = document.getElementById('workflowSelect').value;
            const jobName = document.getElementById('jobSelect').value;
            const dryRun = document.getElementById('dryRun').checked;

            if (!workflowFile) {
                alert('ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„');
                return;
            }

            const logArea = document.getElementById('logArea');
            logArea.textContent = 'ğŸš€ å®Ÿè¡Œä¸­...\n';

            const payload = {
                workflow_file: workflowFile,
                dry_run: dryRun
            };

            if (jobName) {
                payload.job_name = jobName;
            }

            try {
                const response = await fetch('/simulate', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify(payload)
                });

                const result = await response.json();

                logArea.textContent = `
ğŸ“Š å®Ÿè¡Œçµæœ:
æˆåŠŸ: ${result.success ? 'âœ…' : 'âŒ'}
çµ‚äº†ã‚³ãƒ¼ãƒ‰: ${result.return_code}
ã‚¨ãƒ³ã‚¸ãƒ³: ${result.engine}

ğŸ“¤ æ¨™æº–å‡ºåŠ›:
${result.stdout}

ğŸ“¥ æ¨™æº–ã‚¨ãƒ©ãƒ¼:
${result.stderr}

ğŸ”§ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿:
${JSON.stringify(result.metadata, null, 2)}
                `;
            } catch (error) {
                logArea.textContent = `âŒ ã‚¨ãƒ©ãƒ¼: ${error.message}`;
            }
        }

        // ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å‰Šé™¤
        async function deleteWorkflow(filename) {
            if (!confirm(`ãƒ•ã‚¡ã‚¤ãƒ« '${filename}' ã‚’å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ`)) {
                return;
            }

            try {
                const response = await fetch(`/workflows/${filename}`, {
                    method: 'DELETE'
                });

                const result = await response.json();

                if (response.ok) {
                    alert(`âœ… å‰Šé™¤æˆåŠŸ: ${filename}`);
                    loadWorkflows();
                } else {
                    alert(`âŒ å‰Šé™¤å¤±æ•—: ${result.detail}`);
                }
            } catch (error) {
                alert(`âŒ ã‚¨ãƒ©ãƒ¼: ${error.message}`);
            }
        }
    </script>
</body>
</html>
        """
        return HTMLResponse(content=html_content)

    return app


def _generate_recovery_suggestions_from_causes(hangup_causes: List[str], health_report: Any) -> List[str]:
    """ãƒãƒ³ã‚°ã‚¢ãƒƒãƒ—åŸå› ã‹ã‚‰å¾©æ—§ææ¡ˆã‚’ç”Ÿæˆ"""
    suggestions = []

    for cause in hangup_causes:
        cause_lower = cause.lower()

        if "docker" in cause_lower and "socket" in cause_lower:
            suggestions.extend(
                [
                    "Docker Desktopã‚’å†èµ·å‹•ã—ã¦ãã ã•ã„",
                    "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’dockerã‚°ãƒ«ãƒ¼ãƒ—ã«è¿½åŠ : sudo usermod -aG docker $USER",
                    "Docker daemonã®çŠ¶æ…‹ã‚’ç¢ºèª: sudo systemctl status docker",
                ]
            )
        elif "permission" in cause_lower:
            suggestions.extend(
                [
                    "ãƒ•ã‚¡ã‚¤ãƒ«æ¨©é™ã‚’ç¢ºèªã—ã¦ãã ã•ã„: ls -la /var/run/docker.sock",
                    "ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ç¢ºèª: groups",
                    "å¿…è¦ã«å¿œã˜ã¦sudoã§ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„",
                ]
            )
        elif "timeout" in cause_lower:
            suggestions.extend(
                [
                    "ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå€¤ã‚’å¢—åŠ ã•ã›ã¦ãã ã•ã„",
                    "ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„",
                    "ä¸è¦ãªãƒ—ãƒ­ã‚»ã‚¹ã‚’çµ‚äº†ã—ã¦ãã ã•ã„",
                ]
            )
        elif "memory" in cause_lower or "resource" in cause_lower:
            suggestions.extend(
                [
                    "ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ç¢ºèª: free -h",
                    "ä¸è¦ãªDockerã‚³ãƒ³ãƒ†ãƒŠã‚’åœæ­¢: docker container prune",
                    "ã‚·ã‚¹ãƒ†ãƒ ã®è² è·ã‚’ç¢ºèª: top ã¾ãŸã¯ htop",
                ]
            )

    # é‡è¤‡ã‚’é™¤å»
    return list(dict.fromkeys(suggestions))


def _extract_important_details(details: Dict[str, Any]) -> Dict[str, str]:
    """è¨ºæ–­çµæœã®è©³ç´°ã‹ã‚‰é‡è¦ãªæƒ…å ±ã‚’æŠ½å‡º"""
    important = {}

    # é‡è¦ãªã‚­ãƒ¼ã®ãƒªã‚¹ãƒˆ
    important_keys = [
        "version",
        "path",
        "error",
        "stderr",
        "docker_socket_exists",
        "docker_socket_accessible",
        "in_docker_group",
        "is_root",
    ]

    for key in important_keys:
        if key in details:
            value = details[key]
            if isinstance(value, (str, int, float, bool)):
                important[key] = str(value)
            elif isinstance(value, list) and len(value) <= 3:
                important[key] = ", ".join(str(v) for v in value)

    return important


def _generate_next_steps(health_report: Any, hangup_causes: List[str]) -> List[str]:
    """è¨ºæ–­çµæœã«åŸºã¥ã„ã¦æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’ç”Ÿæˆ"""
    steps = []

    # ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹å ´åˆ
    if hasattr(health_report, "has_errors") and health_report.has_errors:
        steps.append("ã¾ãšã€ã‚¨ãƒ©ãƒ¼çŠ¶æ…‹ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ä¿®æ­£ã—ã¦ãã ã•ã„")
        steps.append("ä¿®æ­£å¾Œã€å†åº¦è¨ºæ–­ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„: actions diagnose")

    # è­¦å‘ŠãŒã‚ã‚‹å ´åˆ
    elif hasattr(health_report, "has_warnings") and health_report.has_warnings:
        steps.append("è­¦å‘Šé …ç›®ã‚’ç¢ºèªã—ã€å¯èƒ½ã§ã‚ã‚Œã°ä¿®æ­£ã—ã¦ãã ã•ã„")
        steps.append("ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å®Ÿè¡Œã‚’è©¦ã—ã¦ã¿ã¦ãã ã•ã„")

    # æ­£å¸¸ãªå ´åˆ
    else:
        steps.append("ã‚·ã‚¹ãƒ†ãƒ ã¯æ­£å¸¸ã§ã™ã€‚ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å®Ÿè¡Œã‚’é–‹å§‹ã§ãã¾ã™")
        steps.append("å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆã¯ --enhanced ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„")

    # ãƒãƒ³ã‚°ã‚¢ãƒƒãƒ—åŸå› ãŒã‚ã‚‹å ´åˆ
    if hangup_causes:
        steps.append("ãƒãƒ³ã‚°ã‚¢ãƒƒãƒ—å•é¡Œã®ä¿®æ­£å¾Œã€ãƒ†ã‚¹ãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã§å‹•ä½œç¢ºèªã—ã¦ãã ã•ã„")
        steps.append("å•é¡ŒãŒç¶™ç¶šã™ã‚‹å ´åˆã¯ --create-debug-bundle ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’åé›†ã—ã¦ãã ã•ã„")

    return steps


def main() -> None:
    """CLIã®å®Ÿè¡Œã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""

    cli.main(prog_name="actions")


if __name__ == "__main__":
    main()
