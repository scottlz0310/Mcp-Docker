#!/usr/bin/env python3
"""
ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ï¼š
1. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆé–“ã®ãƒªãƒ³ã‚¯æœ‰åŠ¹æ€§ç¢ºèª
2. ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
3. å¤ã„æƒ…å ±ã‚„çŸ›ç›¾ã™ã‚‹è¨˜è¿°ã®æ¤œå‡º
"""

import argparse
import json
import re
import sys
import tomllib
from dataclasses import dataclass, field
from datetime import datetime, UTC
from pathlib import Path
from typing import Any, Dict, List, Optional

import yaml


@dataclass
class LinkIssue:
    """ãƒªãƒ³ã‚¯ã®å•é¡Œã‚’è¡¨ã™ã‚¯ãƒ©ã‚¹"""

    source_file: Path
    line_number: int
    link_text: str
    target_path: str
    issue_type: str
    description: str


@dataclass
class VersionIssue:
    """ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®å•é¡Œã‚’è¡¨ã™ã‚¯ãƒ©ã‚¹"""

    file_path: Path
    line_number: int
    found_version: str
    expected_version: str
    context: str


@dataclass
class ConsistencyIssue:
    """æ•´åˆæ€§ã®å•é¡Œã‚’è¡¨ã™ã‚¯ãƒ©ã‚¹"""

    file_path: Path
    line_number: int
    issue_type: str
    description: str
    suggestion: Optional[str] = None


@dataclass
class DocumentationReport:
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ãƒ¬ãƒãƒ¼ãƒˆ"""

    timestamp: str
    total_files_checked: int
    link_issues: List[LinkIssue] = field(default_factory=list)
    version_issues: List[VersionIssue] = field(default_factory=list)
    consistency_issues: List[ConsistencyIssue] = field(default_factory=list)

    @property
    def total_issues(self) -> int:
        return len(self.link_issues) + len(self.version_issues) + len(self.consistency_issues)

    @property
    def has_critical_issues(self) -> bool:
        """é‡è¦ãªå•é¡ŒãŒã‚ã‚‹ã‹ã©ã†ã‹"""
        return len(self.link_issues) > 0 or len(self.version_issues) > 0


class DocumentationChecker:
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´åˆæ€§ãƒã‚§ãƒƒã‚«ãƒ¼"""

    def __init__(self, root_path: Path, config_path: Optional[Path] = None):
        self.root_path = root_path
        self.config = self._load_config(config_path)
        self.project_version = self._get_project_version()
        self.markdown_files = self._find_markdown_files()

    def _load_config(self, config_path: Optional[Path]) -> Dict[str, Any]:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        if config_path is None:
            config_path = self.root_path / ".docs-check.yaml"

        if not config_path.exists():
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
            return {
                "exclude_dirs": {
                    ".git",
                    ".mypy_cache",
                    ".pytest_cache",
                    ".ruff_cache",
                    ".venv",
                    "node_modules",
                    "__pycache__",
                    "archive",
                },
                "version_check": {
                    "exclude_patterns": [
                        r"^20\.\d+\.\d+$",
                        r"^24\.\d+\.\d+$",
                        r"^2\.\d+\.\d+$",
                        r"^0\.2\.\d+$",
                        r"^0\.0\.\d+$",
                    ]
                },
            }

        try:
            with open(config_path, "r", encoding="utf-8") as f:
                return yaml.safe_load(f)
        except Exception:
            return {}

    def _get_project_version(self) -> str:
        """pyproject.tomlã‹ã‚‰ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å–å¾—"""
        pyproject_path = self.root_path / "pyproject.toml"
        if not pyproject_path.exists():
            return "unknown"

        try:
            with open(pyproject_path, "rb") as f:
                data = tomllib.load(f)
            return data.get("project", {}).get("version", "unknown")
        except Exception:
            return "unknown"

    def _find_markdown_files(self) -> List[Path]:
        """Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†å¸°çš„ã«æ¤œç´¢"""
        markdown_files = []

        # é™¤å¤–ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—ï¼‰
        exclude_dirs = set(self.config.get("exclude_dirs", []))

        for md_file in self.root_path.rglob("*.md"):
            # é™¤å¤–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒã‚§ãƒƒã‚¯
            if any(part in exclude_dirs for part in md_file.parts):
                continue
            markdown_files.append(md_file)

        return sorted(markdown_files)

    def check_links(self) -> List[LinkIssue]:
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆé–“ã®ãƒªãƒ³ã‚¯æœ‰åŠ¹æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
        issues = []

        # Markdownãƒªãƒ³ã‚¯ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
        link_pattern = re.compile(r"\[([^\]]+)\]\(([^)]+)\)")

        for md_file in self.markdown_files:
            try:
                with open(md_file, "r", encoding="utf-8") as f:
                    lines = f.readlines()

                for line_num, line in enumerate(lines, 1):
                    matches = link_pattern.findall(line)

                    for link_text, target in matches:
                        # å¤–éƒ¨ãƒªãƒ³ã‚¯ã¯ã‚¹ã‚­ãƒƒãƒ—
                        if target.startswith(("http://", "https://", "mailto:")):
                            continue

                        # ã‚¢ãƒ³ã‚«ãƒ¼ãƒªãƒ³ã‚¯ã‚’åˆ†é›¢
                        if "#" in target:
                            target_path, anchor = target.split("#", 1)
                        else:
                            target_path, anchor = target, None

                        if not target_path:  # ã‚¢ãƒ³ã‚«ãƒ¼ã®ã¿ã®å ´åˆ
                            continue

                        # ç›¸å¯¾ãƒ‘ã‚¹ã‚’çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›
                        if target_path.startswith("/"):
                            # ãƒ«ãƒ¼ãƒˆã‹ã‚‰ã®çµ¶å¯¾ãƒ‘ã‚¹
                            full_path = self.root_path / target_path.lstrip("/")
                        else:
                            # ç›¸å¯¾ãƒ‘ã‚¹
                            full_path = (md_file.parent / target_path).resolve()

                        # ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
                        if not full_path.exists():
                            issues.append(
                                LinkIssue(
                                    source_file=md_file,
                                    line_number=line_num,
                                    link_text=link_text,
                                    target_path=target,
                                    issue_type="broken_link",
                                    description=f"ãƒªãƒ³ã‚¯å…ˆãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {full_path}",
                                )
                            )

                        # ã‚¢ãƒ³ã‚«ãƒ¼ã®å­˜åœ¨ç¢ºèªï¼ˆMarkdownãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆï¼‰
                        elif anchor and full_path.suffix == ".md":
                            if not self._check_anchor_exists(full_path, anchor):
                                issues.append(
                                    LinkIssue(
                                        source_file=md_file,
                                        line_number=line_num,
                                        link_text=link_text,
                                        target_path=target,
                                        issue_type="broken_anchor",
                                        description=f"ã‚¢ãƒ³ã‚«ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: #{anchor}",
                                    )
                                )

            except Exception as e:
                issues.append(
                    LinkIssue(
                        source_file=md_file,
                        line_number=0,
                        link_text="",
                        target_path="",
                        issue_type="read_error",
                        description=f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}",
                    )
                )

        return issues

    def _check_anchor_exists(self, file_path: Path, anchor: str) -> bool:
        """Markdownãƒ•ã‚¡ã‚¤ãƒ«å†…ã®ã‚¢ãƒ³ã‚«ãƒ¼ã®å­˜åœ¨ç¢ºèª"""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()

            # ãƒ˜ãƒƒãƒ€ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³
            header_pattern = re.compile(r"^#+\s+(.+)$", re.MULTILINE)
            headers = header_pattern.findall(content)

            # ã‚¢ãƒ³ã‚«ãƒ¼å½¢å¼ã«å¤‰æ›ï¼ˆGitHubå½¢å¼ï¼‰
            for header in headers:
                # ç‰¹æ®Šæ–‡å­—ã‚’é™¤å»ã—ã¦ã‚¢ãƒ³ã‚«ãƒ¼å½¢å¼ã«å¤‰æ›
                anchor_text = re.sub(r"[^\w\s-]", "", header.lower())
                anchor_text = re.sub(r"[-\s]+", "-", anchor_text).strip("-")

                if anchor_text == anchor.lower():
                    return True

            return False

        except Exception:
            return False

    def check_versions(self) -> List[VersionIssue]:
        """ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã®æ•´åˆæ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
        issues = []

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆã‚ˆã‚Šå…·ä½“çš„ã«ï¼‰
        version_patterns = [
            (
                re.compile(r'version["\s]*[:=]["\s]*([0-9]+\.[0-9]+\.[0-9]+)', re.IGNORECASE),
                "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«",
            ),
            (
                re.compile(
                    r'mcp-docker["\s]*[:=]["\s]*v?([0-9]+\.[0-9]+\.[0-9]+)',
                    re.IGNORECASE,
                ),
                "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³",
            ),
            (
                re.compile(r"ãƒªãƒªãƒ¼ã‚¹\s*v?([0-9]+\.[0-9]+\.[0-9]+)", re.IGNORECASE),
                "ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ã‚¸ãƒ§ãƒ³",
            ),
        ]

        for md_file in self.markdown_files:
            try:
                with open(md_file, "r", encoding="utf-8") as f:
                    lines = f.readlines()

                for line_num, line in enumerate(lines, 1):
                    for pattern, context in version_patterns:
                        matches = pattern.findall(line)

                        for version in matches:
                            if version != self.project_version and version != "unknown":
                                # æ˜ã‚‰ã‹ã«ç•°ãªã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ã¿å ±å‘Š
                                if self._is_version_mismatch(version, self.project_version):
                                    issues.append(
                                        VersionIssue(
                                            file_path=md_file,
                                            line_number=line_num,
                                            found_version=version,
                                            expected_version=self.project_version,
                                            context=context,
                                        )
                                    )

            except Exception:
                continue

        return issues

    def _is_version_mismatch(self, found: str, expected: str) -> bool:
        """ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ä¸æ•´åˆã‚’åˆ¤å®š"""
        try:
            # é™¤å¤–ã™ã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—ï¼‰
            excluded_patterns = self.config.get("version_check", {}).get("exclude_patterns", [])

            for pattern in excluded_patterns:
                if re.match(pattern, found):
                    return False

            found_parts = [int(x) for x in found.split(".")]
            expected_parts = [int(x) for x in expected.split(".")]

            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¨æ˜ã‚‰ã‹ã«ç•°ãªã‚‹å ´åˆã®ã¿å ±å‘Š
            # ãƒ¡ã‚¸ãƒ£ãƒ¼ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒå¤§ããç•°ãªã‚‹å ´åˆ
            if abs(found_parts[0] - expected_parts[0]) > 1:
                return True

            # åŒã˜ãƒ¡ã‚¸ãƒ£ãƒ¼ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ãƒã‚¤ãƒŠãƒ¼ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒå¤§ããç•°ãªã‚‹å ´åˆ
            if found_parts[0] == expected_parts[0] and abs(found_parts[1] - expected_parts[1]) > 2:
                return True

            return False

        except (ValueError, IndexError):
            return False

    def check_consistency(self) -> List[ConsistencyIssue]:
        """å¤ã„æƒ…å ±ã‚„çŸ›ç›¾ã™ã‚‹è¨˜è¿°ã‚’ãƒã‚§ãƒƒã‚¯"""
        issues = []

        # å¤ã„æƒ…å ±ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
        outdated_patterns = [
            (
                re.compile(r"pip\s+install", re.IGNORECASE),
                "pipä½¿ç”¨",
                "uvã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„",
            ),
            (
                re.compile(r"npm\s+install", re.IGNORECASE),
                "npmä½¿ç”¨",
                "uvã¾ãŸã¯é©åˆ‡ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„",
            ),
            (
                re.compile(r"python\s+-m\s+pip", re.IGNORECASE),
                "pipä½¿ç”¨",
                "uvã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„",
            ),
            (
                re.compile(r"requirements\.txt", re.IGNORECASE),
                "requirements.txt",
                "pyproject.tomlã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„",
            ),
        ]

        # çŸ›ç›¾ã™ã‚‹è¨˜è¿°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
        contradiction_patterns = [
            (
                re.compile(r"Docker\s+Desktop.*å¿…é ˆ", re.IGNORECASE),
                "Docker Desktopå¿…é ˆ",
                "Docker Engineã§ã‚‚å‹•ä½œã—ã¾ã™",
            ),
            (
                re.compile(r"root.*æ¨©é™.*å¿…è¦", re.IGNORECASE),
                "rootæ¨©é™å¿…è¦",
                "rootless Dockerã‚’æ¨å¥¨ã—ã¦ã„ã¾ã™",
            ),
        ]

        for md_file in self.markdown_files:
            try:
                with open(md_file, "r", encoding="utf-8") as f:
                    lines = f.readlines()

                for line_num, line in enumerate(lines, 1):
                    # å¤ã„æƒ…å ±ã®ãƒã‚§ãƒƒã‚¯
                    for pattern, issue_type, suggestion in outdated_patterns:
                        if pattern.search(line):
                            issues.append(
                                ConsistencyIssue(
                                    file_path=md_file,
                                    line_number=line_num,
                                    issue_type=f"outdated_{issue_type}",
                                    description=f"å¤ã„æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã¾ã™: {issue_type}",
                                    suggestion=suggestion,
                                )
                            )

                    # çŸ›ç›¾ã™ã‚‹è¨˜è¿°ã®ãƒã‚§ãƒƒã‚¯
                    for pattern, issue_type, suggestion in contradiction_patterns:
                        if pattern.search(line):
                            issues.append(
                                ConsistencyIssue(
                                    file_path=md_file,
                                    line_number=line_num,
                                    issue_type=f"contradiction_{issue_type}",
                                    description=f"çŸ›ç›¾ã™ã‚‹è¨˜è¿°ãŒã‚ã‚Šã¾ã™: {issue_type}",
                                    suggestion=suggestion,
                                )
                            )

            except Exception:
                continue

        return issues

    def generate_report(self) -> DocumentationReport:
        """åŒ…æ‹¬çš„ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´åˆæ€§ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        print("ğŸ” ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã‚’é–‹å§‹...")

        print("ğŸ“‹ ãƒªãƒ³ã‚¯æœ‰åŠ¹æ€§ã‚’ãƒã‚§ãƒƒã‚¯ä¸­...")
        link_issues = self.check_links()

        print("ğŸ”¢ ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•´åˆæ€§ã‚’ãƒã‚§ãƒƒã‚¯ä¸­...")
        version_issues = self.check_versions()

        print("ğŸ“ å†…å®¹æ•´åˆæ€§ã‚’ãƒã‚§ãƒƒã‚¯ä¸­...")
        consistency_issues = self.check_consistency()

        return DocumentationReport(
            timestamp=datetime.now(UTC).isoformat().replace("+00:00", "Z"),
            total_files_checked=len(self.markdown_files),
            link_issues=link_issues,
            version_issues=version_issues,
            consistency_issues=consistency_issues,
        )


def print_report(
    report: DocumentationReport,
    verbose: bool = False,
    ci_mode: bool = False,
    fix_suggestions: bool = False,
) -> None:
    """ãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤º"""
    if ci_mode:
        # CI/CDç’°å¢ƒå‘ã‘ã®ç°¡æ½”ãªå‡ºåŠ›
        print(f"docs-check: {report.total_files_checked} files, {report.total_issues} issues")
        if report.has_critical_issues:
            print(
                f"docs-check: CRITICAL - {len(report.link_issues)} broken links, {len(report.version_issues)} version mismatches"
            )
        return

    print("\nğŸ“Š ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯çµæœ")
    print(f"â° å®Ÿè¡Œæ™‚åˆ»: {report.timestamp}")
    print(f"ğŸ“ ãƒã‚§ãƒƒã‚¯å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {report.total_files_checked}")
    print(f"ğŸš¨ ç·å•é¡Œæ•°: {report.total_issues}")

    if report.link_issues:
        print(f"\nğŸ”— ãƒªãƒ³ã‚¯ã®å•é¡Œ ({len(report.link_issues)}ä»¶):")
        for issue in report.link_issues:
            rel_path = issue.source_file.relative_to(Path.cwd())
            print(f"  âŒ {rel_path}:{issue.line_number}")
            print(f"     ãƒªãƒ³ã‚¯: [{issue.link_text}]({issue.target_path})")
            print(f"     å•é¡Œ: {issue.description}")
            if verbose:
                print(f"     ã‚¿ã‚¤ãƒ—: {issue.issue_type}")
            if fix_suggestions and issue.issue_type == "broken_link":
                print("     ğŸ’¡ ä¿®æ­£ææ¡ˆ: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã€æ­£ã—ã„ãƒ‘ã‚¹ã«ä¿®æ­£ã—ã¦ãã ã•ã„")

    if report.version_issues:
        print(f"\nğŸ”¢ ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®å•é¡Œ ({len(report.version_issues)}ä»¶):")
        for v_issue in report.version_issues:
            rel_path = v_issue.file_path.relative_to(Path.cwd())
            print(f"  âŒ {rel_path}:{v_issue.line_number}")
            print(f"     ç™ºè¦‹: {v_issue.found_version} â†’ æœŸå¾…: {v_issue.expected_version}")
            print(f"     ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {v_issue.context}")
            if fix_suggestions:
                print(f"     ğŸ’¡ ä¿®æ­£ææ¡ˆ: ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ {v_issue.expected_version} ã«æ›´æ–°ã—ã¦ãã ã•ã„")

    if report.consistency_issues:
        print(f"\nğŸ“ æ•´åˆæ€§ã®å•é¡Œ ({len(report.consistency_issues)}ä»¶):")
        for c_issue in report.consistency_issues:
            rel_path = c_issue.file_path.relative_to(Path.cwd())
            print(f"  âš ï¸  {rel_path}:{c_issue.line_number}")
            print(f"     å•é¡Œ: {c_issue.description}")
            if c_issue.suggestion:
                print(f"     ææ¡ˆ: {c_issue.suggestion}")

    if fix_suggestions and report.total_issues > 0:
        print("\nğŸ”§ ä¿®æ­£ã‚³ãƒãƒ³ãƒ‰ä¾‹:")
        if report.link_issues:
            print("  # å£Šã‚ŒãŸãƒªãƒ³ã‚¯ã®ä¿®æ­£")
            print(
                "  find docs -name '*.md' -exec grep -l 'QUICK_START.md' {} \\; | xargs sed -i 's|QUICK_START.md|../QUICK_START.md|g'"
            )
        if report.version_issues:
            print("  # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã®ä¸€æ‹¬æ›´æ–°")
            print(
                f"  find . -name '*.md' -exec sed -i 's/version: [0-9]\\+\\.[0-9]\\+\\.[0-9]\\+/version: {report.version_issues[0].expected_version if report.version_issues else '1.2.0'}/g' {{}} \\;"
            )

    if report.total_issues == 0:
        print("\nâœ… å•é¡Œã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼")
    elif report.has_critical_issues:
        print(f"\nğŸš¨ é‡è¦ãªå•é¡ŒãŒ {len(report.link_issues) + len(report.version_issues)} ä»¶è¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")
        print("   ä¿®æ­£ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚")
    else:
        print(f"\nâš ï¸  è»½å¾®ãªå•é¡ŒãŒ {len(report.consistency_issues)} ä»¶è¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")
        print("   å¿…è¦ã«å¿œã˜ã¦ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚")


def save_report_json(report: DocumentationReport, output_path: Path) -> None:
    """ãƒ¬ãƒãƒ¼ãƒˆã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""

    def convert_to_dict(obj: Any) -> Any:
        if hasattr(obj, "__dict__"):
            result: Dict[str, Any] = {}
            for key, value in obj.__dict__.items():
                if isinstance(value, Path):
                    result[key] = str(value)
                elif isinstance(value, list):
                    result[key] = [convert_to_dict(item) for item in value]
                else:
                    result[key] = value
            return result
        return obj

    report_dict = convert_to_dict(report)

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(report_dict, f, ensure_ascii=False, indent=2)

    print(f"ğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description="ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ãƒ„ãƒ¼ãƒ«",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  %(prog)s                          # åŸºæœ¬ãƒã‚§ãƒƒã‚¯
  %(prog)s --verbose                # è©³ç´°è¡¨ç¤º
  %(prog)s --output report.json     # JSONãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
  %(prog)s --root /path/to/project  # åˆ¥ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ãƒã‚§ãƒƒã‚¯
        """,
    )

    parser.add_argument(
        "--root",
        type=Path,
        default=Path.cwd(),
        help="ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª)",
    )

    parser.add_argument("--output", type=Path, help="JSONãƒ¬ãƒãƒ¼ãƒˆã®å‡ºåŠ›å…ˆãƒ•ã‚¡ã‚¤ãƒ«")

    parser.add_argument("--verbose", "-v", action="store_true", help="è©³ç´°ãªæƒ…å ±ã‚’è¡¨ç¤º")

    parser.add_argument(
        "--fail-on-issues",
        action="store_true",
        help="å•é¡ŒãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã«çµ‚äº†ã‚³ãƒ¼ãƒ‰1ã§çµ‚äº†",
    )

    parser.add_argument("--ci-mode", action="store_true", help="CI/CDç’°å¢ƒå‘ã‘ã®ç°¡æ½”ãªå‡ºåŠ›")

    parser.add_argument("--fix-suggestions", action="store_true", help="ä¿®æ­£ææ¡ˆã‚’è¡¨ç¤º")

    parser.add_argument("--config", type=Path, help="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: .docs-check.yaml)")

    args = parser.parse_args()

    try:
        checker = DocumentationChecker(args.root, args.config)
        report = checker.generate_report()

        print_report(report, args.verbose, args.ci_mode, args.fix_suggestions)

        if args.output:
            save_report_json(report, args.output)

        # çµ‚äº†ã‚³ãƒ¼ãƒ‰ã®æ±ºå®š
        if args.fail_on_issues and report.has_critical_issues:
            sys.exit(1)

    except KeyboardInterrupt:
        print("\nâš ï¸  ãƒã‚§ãƒƒã‚¯ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚")
        sys.exit(130)
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        if args.verbose:
            import traceback

            traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
