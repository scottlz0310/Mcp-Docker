#!/bin/bash
# GitHub Actions Simulator - ãƒãƒ³ã‚°ã‚¢ãƒƒãƒ—ãƒªã‚°ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
#
# ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ç¶™ç¶šçš„ã«ãƒãƒ³ã‚°ã‚¢ãƒƒãƒ—ä¿®æ­£ã®åŠ¹æœã‚’ç›£è¦–ã—ã€
# ãƒªã‚°ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ã‚’æ—©æœŸã«æ¤œå‡ºã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚

set -euo pipefail

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆè¨­å®š
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)"
OUTPUT_DIR="$PROJECT_ROOT/output/regression-tests"
TIMESTAMP=$(date -u +"%Y%m%d_%H%M%S")

# ãƒ­ã‚°è¨­å®š
LOG_FILE="$OUTPUT_DIR/regression-test-$TIMESTAMP.log"
export PERFORMANCE_LOG="$OUTPUT_DIR/performance-$TIMESTAMP.json"

# è‰²ä»˜ããƒ­ã‚°é–¢æ•°
log_info() {
    echo -e "\033[32m[INFO]\033[0m $1" | tee -a "$LOG_FILE"
}

log_warn() {
    echo -e "\033[33m[WARN]\033[0m $1" | tee -a "$LOG_FILE"
}

log_error() {
    echo -e "\033[31m[ERROR]\033[0m $1" | tee -a "$LOG_FILE"
}

log_debug() {
    if [[ "${DEBUG:-false}" == "true" ]]; then
        echo -e "\033[36m[DEBUG]\033[0m $1" | tee -a "$LOG_FILE"
    fi
}

# ä½¿ç”¨æ–¹æ³•è¡¨ç¤º
show_usage() {
    cat << EOF
ä½¿ç”¨æ–¹æ³•: $0 [ã‚ªãƒ—ã‚·ãƒ§ãƒ³]

ã‚ªãƒ—ã‚·ãƒ§ãƒ³:
    -h, --help              ã“ã®ãƒ˜ãƒ«ãƒ—ã‚’è¡¨ç¤º
    -v, --verbose           è©³ç´°ãƒ­ã‚°ã‚’æœ‰åŠ¹åŒ–
    -q, --quiet             é™éŸ³ãƒ¢ãƒ¼ãƒ‰
    -t, --timeout SECONDS   ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚é–“ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1800ç§’ï¼‰
    -o, --output DIR        å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: output/regression-testsï¼‰
    --performance-only      ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã®ã¿å®Ÿè¡Œ
    --regression-only       ãƒªã‚°ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆã®ã¿å®Ÿè¡Œ
    --baseline              ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®šãƒ¢ãƒ¼ãƒ‰
    --compare-with FILE     æŒ‡å®šãƒ•ã‚¡ã‚¤ãƒ«ã¨ã®æ¯”è¼ƒ

ä¾‹:
    $0                      # å…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    $0 --performance-only   # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã®ã¿
    $0 --baseline          # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®š
    $0 --compare-with output/regression-tests/baseline.json
EOF
}

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
VERBOSE=false
QUIET=false
TIMEOUT=1800
PERFORMANCE_ONLY=false
REGRESSION_ONLY=false
BASELINE_MODE=false
COMPARE_FILE=""

# ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°è§£æ
while [[ $# -gt 0 ]]; do
    case $1 in
        -h|--help)
            show_usage
            exit 0
            ;;
        -v|--verbose)
            export VERBOSE=true
            DEBUG=true
            shift
            ;;
        -q|--quiet)
            export QUIET=true
            shift
            ;;
        -t|--timeout)
            TIMEOUT="$2"
            shift 2
            ;;
        -o|--output)
            OUTPUT_DIR="$2"
            shift 2
            ;;
        --performance-only)
            PERFORMANCE_ONLY=true
            shift
            ;;
        --regression-only)
            REGRESSION_ONLY=true
            shift
            ;;
        --baseline)
            BASELINE_MODE=true
            shift
            ;;
        --compare-with)
            COMPARE_FILE="$2"
            shift 2
            ;;
        *)
            log_error "ä¸æ˜ãªã‚ªãƒ—ã‚·ãƒ§ãƒ³: $1"
            show_usage
            exit 1
            ;;
    esac
done

# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
mkdir -p "$OUTPUT_DIR"

# ç’°å¢ƒãƒã‚§ãƒƒã‚¯
check_environment() {
    log_info "ç’°å¢ƒãƒã‚§ãƒƒã‚¯é–‹å§‹"

    # å¿…è¦ãªã‚³ãƒãƒ³ãƒ‰ãƒã‚§ãƒƒã‚¯
    local required_commands=("docker" "uv")
    for cmd in "${required_commands[@]}"; do
        if ! command -v "$cmd" &> /dev/null; then
            log_error "å¿…è¦ãªã‚³ãƒãƒ³ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: $cmd"
            exit 1
        fi
        log_debug "$cmd: $(command -v "$cmd")"
    done

    # Pythonç’°å¢ƒãƒã‚§ãƒƒã‚¯
    log_debug "Python: $(uv run python --version)"

    # Dockerç’°å¢ƒãƒã‚§ãƒƒã‚¯
    if ! docker info &> /dev/null; then
        log_error "Docker ãƒ‡ãƒ¼ãƒ¢ãƒ³ã«æ¥ç¶šã§ãã¾ã›ã‚“"
        exit 1
    fi
    log_debug "Docker: $(docker --version)"

    # uvç’°å¢ƒãƒã‚§ãƒƒã‚¯
    if ! uv --version &> /dev/null; then
        log_error "uv ãŒæ­£ã—ãã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“"
        exit 1
    fi
    log_debug "uv: $(uv --version)"

    log_info "ç’°å¢ƒãƒã‚§ãƒƒã‚¯å®Œäº†"
}

# ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±åé›†
collect_system_info() {
    log_info "ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±åé›†"

    local system_info_file="$OUTPUT_DIR/system-info-$TIMESTAMP.json"

    uv run python << EOF > "$system_info_file"
import json
import platform
import psutil
import subprocess
from datetime import datetime

system_info = {
    "timestamp": datetime.utcnow().isoformat(),
    "platform": {
        "system": platform.system(),
        "release": platform.release(),
        "version": platform.version(),
        "machine": platform.machine(),
        "processor": platform.processor()
    },
    "python": {
        "version": platform.python_version(),
        "implementation": platform.python_implementation()
    },
    "resources": {
        "cpu_count": psutil.cpu_count(),
        "cpu_count_logical": psutil.cpu_count(logical=True),
        "memory_total": psutil.virtual_memory().total,
        "disk_total": psutil.disk_usage('/').total
    }
}

# Dockeræƒ…å ±
try:
    docker_version = subprocess.check_output(['docker', '--version'], text=True).strip()
    system_info["docker"] = {"version": docker_version}
except:
    system_info["docker"] = {"version": "unknown"}

print(json.dumps(system_info, indent=2))
EOF

    log_debug "ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’ä¿å­˜: $system_info_file"
}

# ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®š
run_baseline_measurement() {
    log_info "ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®šé–‹å§‹"

    local baseline_file="$OUTPUT_DIR/baseline-$TIMESTAMP.json"

    (timeout "$TIMEOUT" uv run python << EOF
import json
import sys
import time
import psutil
from datetime import datetime
from services.actions.diagnostic import DiagnosticService
from services.actions.hangup_detector import HangupDetector
from services.actions.logger import ActionsLogger

logger = ActionsLogger(verbose=True)

baseline_results = {
    "timestamp": datetime.utcnow().isoformat(),
    "test_type": "baseline",
    "measurements": {}
}

print("ğŸ“Š ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®šå®Ÿè¡Œ", file=sys.stderr)

# è¨ºæ–­ã‚µãƒ¼ãƒ“ã‚¹ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³
print("1. è¨ºæ–­ã‚µãƒ¼ãƒ“ã‚¹æ¸¬å®š", file=sys.stderr)
process = psutil.Process()
start_memory = process.memory_info().rss / 1024 / 1024

start_time = time.time()
service = DiagnosticService(logger=logger)
health_report = service.run_comprehensive_health_check()
end_time = time.time()

end_memory = process.memory_info().rss / 1024 / 1024

baseline_results["measurements"]["diagnostic_service"] = {
    "duration_seconds": end_time - start_time,
    "memory_start_mb": start_memory,
    "memory_end_mb": end_memory,
    "memory_delta_mb": end_memory - start_memory,
    "status": str(health_report.overall_status)
}

# ãƒãƒ³ã‚°ã‚¢ãƒƒãƒ—æ¤œå‡ºãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³
print("2. ãƒãƒ³ã‚°ã‚¢ãƒƒãƒ—æ¤œå‡ºæ¸¬å®š", file=sys.stderr)
start_memory = process.memory_info().rss / 1024 / 1024

start_time = time.time()
detector = HangupDetector(logger=logger)
analysis = detector.analyze_hangup_conditions()
end_time = time.time()

end_memory = process.memory_info().rss / 1024 / 1024

baseline_results["measurements"]["hangup_detector"] = {
    "duration_seconds": end_time - start_time,
    "memory_start_mb": start_memory,
    "memory_end_mb": end_memory,
    "memory_delta_mb": end_memory - start_memory,
    "issues_found": len(analysis.issues)
}

# Dockerçµ±åˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³
print("3. Dockerçµ±åˆæ¸¬å®š", file=sys.stderr)
start_time = time.time()
docker_issues = detector.detect_docker_socket_issues()
end_time = time.time()

baseline_results["measurements"]["docker_integration"] = {
    "duration_seconds": end_time - start_time,
    "issues_found": len(docker_issues)
}

print(json.dumps(baseline_results, indent=2))
EOF
    ) > "$baseline_file"

    if [[ -f "$baseline_file" ]]; then
        log_info "ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®šå®Œäº†: $baseline_file"

        # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¨ã—ã¦ã‚³ãƒ”ãƒ¼
        cp "$baseline_file" "$OUTPUT_DIR/baseline.json"
        log_debug "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°"
    else
        log_error "ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®šã«å¤±æ•—ã—ã¾ã—ãŸ"
        exit 1
    fi
}

# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
run_performance_tests() {
    log_info "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹"

    local performance_file="$OUTPUT_DIR/performance-$TIMESTAMP.json"

    (timeout "$TIMEOUT" uv run python << EOF
import json
import time
import psutil
import threading
from datetime import datetime
from services.actions.diagnostic import DiagnosticService
from services.actions.hangup_detector import HangupDetector
from services.actions.logger import ActionsLogger

logger = ActionsLogger(verbose=True)

performance_results = {
    "timestamp": datetime.utcnow().isoformat(),
    "test_type": "performance",
    "test_duration_seconds": 300,  # 5åˆ†é–“ã®ãƒ†ã‚¹ãƒˆ
    "measurements": []
}

print("âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆ5åˆ†é–“ï¼‰", file=sys.stderr)

def performance_worker(worker_id, duration=300):
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆãƒ¯ãƒ¼ã‚«ãƒ¼"""
    start_time = time.time()
    measurements = []

    while time.time() - start_time < duration:
        measurement_start = time.time()

        try:
            # ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹æ¸¬å®š
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()

            # è¨ºæ–­ã‚µãƒ¼ãƒ“ã‚¹å®Ÿè¡Œ
            service = DiagnosticService(logger=logger)
            diagnostic_start = time.time()
            health_report = service.run_comprehensive_health_check()
            diagnostic_duration = time.time() - diagnostic_start

            # ãƒãƒ³ã‚°ã‚¢ãƒƒãƒ—æ¤œå‡ºå®Ÿè¡Œ
            detector = HangupDetector(logger=logger)
            detection_start = time.time()
            analysis = detector.analyze_hangup_conditions()
            detection_duration = time.time() - detection_start

            measurement = {
                "timestamp": datetime.utcnow().isoformat(),
                "worker_id": worker_id,
                "system_resources": {
                    "cpu_percent": cpu_percent,
                    "memory_percent": memory.percent,
                    "memory_used_mb": memory.used / 1024 / 1024
                },
                "performance": {
                    "diagnostic_duration": diagnostic_duration,
                    "detection_duration": detection_duration
                },
                "results": {
                    "health_status": str(health_report.overall_status),
                    "issues_detected": len(analysis.issues)
                }
            }

            measurements.append(measurement)

            # æ¬¡ã®æ¸¬å®šã¾ã§å°‘ã—å¾…æ©Ÿ
            elapsed = time.time() - measurement_start
            sleep_time = max(0, 10 - elapsed)  # 10ç§’é–“éš”
            if sleep_time > 0:
                time.sleep(sleep_time)

        except Exception as e:
            print(f"Worker {worker_id} ã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
            time.sleep(10)

    return measurements

# å˜ä¸€ãƒ¯ãƒ¼ã‚«ãƒ¼ã§å®Ÿè¡Œï¼ˆCIç’°å¢ƒã§ã®å®‰å®šæ€§ã‚’é‡è¦–ï¼‰
measurements = performance_worker(0, 300)
performance_results["measurements"] = measurements

# çµ±è¨ˆè¨ˆç®—
if measurements:
    diagnostic_times = [m["performance"]["diagnostic_duration"] for m in measurements]
    detection_times = [m["performance"]["detection_duration"] for m in measurements]
    cpu_usage = [m["system_resources"]["cpu_percent"] for m in measurements]
    memory_usage = [m["system_resources"]["memory_percent"] for m in measurements]

    performance_results["statistics"] = {
        "total_measurements": len(measurements),
        "diagnostic_performance": {
            "avg_duration": sum(diagnostic_times) / len(diagnostic_times),
            "max_duration": max(diagnostic_times),
            "min_duration": min(diagnostic_times)
        },
        "detection_performance": {
            "avg_duration": sum(detection_times) / len(detection_times),
            "max_duration": max(detection_times),
            "min_duration": min(detection_times)
        },
        "system_resources": {
            "avg_cpu_percent": sum(cpu_usage) / len(cpu_usage),
            "max_cpu_percent": max(cpu_usage),
            "avg_memory_percent": sum(memory_usage) / len(memory_usage),
            "max_memory_percent": max(memory_usage)
        }
    }

print(json.dumps(performance_results, indent=2))
EOF
    ) > "$performance_file"

    if [[ -f "$performance_file" ]]; then
        log_info "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Œäº†: $performance_file"
    else
        log_error "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ"
        exit 1
    fi
}

# ãƒªã‚°ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
run_regression_tests() {
    log_info "ãƒªã‚°ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆé–‹å§‹"

    local regression_file="$OUTPUT_DIR/regression-$TIMESTAMP.json"

    (timeout "$TIMEOUT" uv run python << EOF
import json
from datetime import datetime
from services.actions.diagnostic import DiagnosticService
from services.actions.hangup_detector import HangupDetector
from services.actions.logger import ActionsLogger

logger = ActionsLogger(verbose=True)

regression_results = {
    "timestamp": datetime.utcnow().isoformat(),
    "test_type": "regression",
    "tests": {}
}

print("ğŸ”„ ãƒªã‚°ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ", file=sys.stderr)

service = DiagnosticService(logger=logger)
detector = HangupDetector(logger=logger)

# æ—¢çŸ¥ã®ä¿®æ­£æ¸ˆã¿å•é¡Œã®ãƒªã‚¹ãƒˆ
fixed_issues = [
    {
        "name": "docker_socket_communication",
        "description": "Docker Socketé€šä¿¡å•é¡Œ",
        "test_function": lambda: service.check_docker_connectivity()
    },
    {
        "name": "subprocess_deadlock",
        "description": "ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯",
        "test_function": lambda: detector.detect_subprocess_deadlock()
    },
    {
        "name": "timeout_handling",
        "description": "ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå‡¦ç†å•é¡Œ",
        "test_function": lambda: detector.detect_timeout_problems()
    },
    {
        "name": "permission_issues",
        "description": "æ¨©é™å•é¡Œ",
        "test_function": lambda: detector.detect_permission_issues()
    }
]

regression_found = False

for issue in fixed_issues:
    print(f"ãƒ†ã‚¹ãƒˆ: {issue['description']}", file=sys.stderr)

    try:
        if issue["name"] == "docker_socket_communication":
            result = issue["test_function"]()
            test_passed = result.status != "ERROR"
            details = {"status": result.status, "message": result.message}
        else:
            issues = issue["test_function"]()
            critical_issues = [i for i in issues if i.severity.value >= 3]
            test_passed = len(critical_issues) == 0
            details = {
                "total_issues": len(issues),
                "critical_issues": len(critical_issues),
                "issue_titles": [i.title for i in critical_issues]
            }

        regression_results["tests"][issue["name"]] = {
            "description": issue["description"],
            "passed": test_passed,
            "details": details
        }

        if not test_passed:
            regression_found = True
            print(f"âŒ å›å¸°æ¤œå‡º: {issue['description']}", file=sys.stderr)
        else:
            print(f"âœ… å•é¡Œãªã—: {issue['description']}", file=sys.stderr)

    except Exception as e:
        regression_results["tests"][issue["name"]] = {
            "description": issue["description"],
            "passed": False,
            "error": str(e)
        }
        regression_found = True
        print(f"âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {issue['description']} - {e}", file=sys.stderr)

regression_results["regression_detected"] = regression_found
regression_results["summary"] = {
    "total_tests": len(fixed_issues),
    "passed_tests": sum(1 for test in regression_results["tests"].values() if test["passed"]),
    "failed_tests": sum(1 for test in regression_results["tests"].values() if not test["passed"])
}

print(json.dumps(regression_results, indent=2))
EOF
    ) > "$regression_file"

    if [[ -f "$regression_file" ]]; then
        log_info "ãƒªã‚°ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆå®Œäº†: $regression_file"

        # ãƒªã‚°ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ¤œå‡ºãƒã‚§ãƒƒã‚¯
        if uv run python -c "
import json
with open('$regression_file') as f:
    data = json.load(f)
exit(1 if data.get('regression_detected', False) else 0)
"; then
            log_info "ãƒªã‚°ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ¤œå‡ºãªã—"
        else
            log_warn "ãƒªã‚°ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ"
            return 1
        fi
    else
        log_error "ãƒªã‚°ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ"
        exit 1
    fi
}

# çµæœæ¯”è¼ƒ
compare_results() {
    if [[ -z "$COMPARE_FILE" ]]; then
        log_debug "æ¯”è¼ƒãƒ•ã‚¡ã‚¤ãƒ«ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
        return 0
    fi

    if [[ ! -f "$COMPARE_FILE" ]]; then
        log_error "æ¯”è¼ƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: $COMPARE_FILE"
        return 1
    fi

    log_info "çµæœæ¯”è¼ƒé–‹å§‹: $COMPARE_FILE"

    local latest_performance
    latest_performance=$(find "$OUTPUT_DIR" -name "performance-*.json" -type f -printf '%T@ %p\n' 2>/dev/null | sort -nr | head -1 | cut -d' ' -f2-)

    if [[ -z "$latest_performance" ]]; then
        log_warn "æ¯”è¼ƒç”¨ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"
        return 1
    fi

    uv run python << EOF
import json

# ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
with open("$COMPARE_FILE") as f:
    baseline = json.load(f)

# ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
with open("$latest_performance") as f:
    current = json.load(f)

print("ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒçµæœ")

if "measurements" in baseline and "statistics" in current:
    # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‹ã‚‰çµ±è¨ˆã‚’è¨ˆç®—
    if "diagnostic_service" in baseline["measurements"]:
        baseline_diagnostic = baseline["measurements"]["diagnostic_service"]["duration_seconds"]
        current_diagnostic = current["statistics"]["diagnostic_performance"]["avg_duration"]

        change_percent = ((current_diagnostic - baseline_diagnostic) / baseline_diagnostic) * 100
        print(f"è¨ºæ–­ã‚µãƒ¼ãƒ“ã‚¹æ€§èƒ½å¤‰åŒ–: {change_percent:+.1f}% ({baseline_diagnostic:.2f}s â†’ {current_diagnostic:.2f}s)")

        if abs(change_percent) > 20:
            print(f"âš ï¸  å¤§ããªæ€§èƒ½å¤‰åŒ–ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ: {change_percent:+.1f}%")

    if "hangup_detector" in baseline["measurements"]:
        baseline_detection = baseline["measurements"]["hangup_detector"]["duration_seconds"]
        current_detection = current["statistics"]["detection_performance"]["avg_duration"]

        change_percent = ((current_detection - baseline_detection) / baseline_detection) * 100
        print(f"ãƒãƒ³ã‚°ã‚¢ãƒƒãƒ—æ¤œå‡ºæ€§èƒ½å¤‰åŒ–: {change_percent:+.1f}% ({baseline_detection:.2f}s â†’ {current_detection:.2f}s)")

        if abs(change_percent) > 20:
            print(f"âš ï¸  å¤§ããªæ€§èƒ½å¤‰åŒ–ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ: {change_percent:+.1f}%")

print("âœ… æ¯”è¼ƒå®Œäº†")
EOF

    log_info "çµæœæ¯”è¼ƒå®Œäº†"
}

# ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
generate_report() {
    log_info "ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹"

    local report_file="$OUTPUT_DIR/regression-report-$TIMESTAMP.md"

    cat > "$report_file" << EOF
# ãƒãƒ³ã‚°ã‚¢ãƒƒãƒ—ãƒªã‚°ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆçµæœãƒ¬ãƒãƒ¼ãƒˆ

## å®Ÿè¡Œæ¦‚è¦
- **å®Ÿè¡Œæ—¥æ™‚**: $(date -u +"%Y-%m-%d %H:%M:%S UTC")
- **å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰**: $(if [[ "$BASELINE_MODE" == "true" ]]; then echo "ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®š"; elif [[ "$PERFORMANCE_ONLY" == "true" ]]; then echo "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã®ã¿"; elif [[ "$REGRESSION_ONLY" == "true" ]]; then echo "ãƒªã‚°ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆã®ã¿"; else echo "å®Œå…¨ãƒ†ã‚¹ãƒˆ"; fi)
- **ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ**: ${TIMEOUT}ç§’
- **å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª**: $OUTPUT_DIR

## å®Ÿè¡Œã•ã‚ŒãŸãƒ†ã‚¹ãƒˆ

EOF

    # å„ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèªã¨ã‚µãƒãƒªãƒ¼è¿½åŠ 
    {
        if [[ -f "$OUTPUT_DIR/baseline-$TIMESTAMP.json" ]]; then
            echo "### ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®š"
            echo "âœ… å®Ÿè¡Œæ¸ˆã¿ - \`baseline-$TIMESTAMP.json\`"
            echo ""
        fi

        if [[ -f "$OUTPUT_DIR/performance-$TIMESTAMP.json" ]]; then
            echo "### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"
            echo "âœ… å®Ÿè¡Œæ¸ˆã¿ - \`performance-$TIMESTAMP.json\`"
            echo ""
        fi

        if [[ -f "$OUTPUT_DIR/regression-$TIMESTAMP.json" ]]; then
            echo "### ãƒªã‚°ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ"
            echo "âœ… å®Ÿè¡Œæ¸ˆã¿ - \`regression-$TIMESTAMP.json\`"
            echo ""
        fi
    } >> "$report_file"

    cat >> "$report_file" << EOF
## æ¨å¥¨äº‹é …

### ç¶™ç¶šçš„ç›£è¦–
- å®šæœŸçš„ãªãƒªã‚°ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŸºæº–å€¤ã®è¦‹ç›´ã—
- æ–°ã—ã„ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã®è¿½åŠ 

### å•é¡Œå¯¾å¿œ
- ãƒªã‚°ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ¤œå‡ºæ™‚ã®è¿…é€Ÿãªå¯¾å¿œ
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŠ£åŒ–ã®åŸå› åˆ†æ
- ä¿®æ­£å¾Œã®å†ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

## ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§

EOF

    # ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆè¿½åŠ 
    find "$OUTPUT_DIR" -name "*$TIMESTAMP*" -type f | while read -r file; do
        echo "- \`$(basename "$file")\`" >> "$report_file"
    done

    log_info "ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: $report_file"
}

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
main() {
    log_info "ãƒãƒ³ã‚°ã‚¢ãƒƒãƒ—ãƒªã‚°ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆé–‹å§‹"
    log_info "ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: $TIMESTAMP"

    # ç’°å¢ƒãƒã‚§ãƒƒã‚¯
    check_environment

    # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±åé›†
    collect_system_info

    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    if [[ "$BASELINE_MODE" == "true" ]]; then
        run_baseline_measurement
    elif [[ "$PERFORMANCE_ONLY" == "true" ]]; then
        run_performance_tests
    elif [[ "$REGRESSION_ONLY" == "true" ]]; then
        run_regression_tests
    else
        # å…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        if [[ ! -f "$OUTPUT_DIR/baseline.json" ]]; then
            log_info "ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„ãŸã‚ã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®šã‚’å®Ÿè¡Œã—ã¾ã™"
            run_baseline_measurement
        fi

        run_performance_tests
        run_regression_tests
    fi

    # çµæœæ¯”è¼ƒ
    compare_results

    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    generate_report

    log_info "ãƒãƒ³ã‚°ã‚¢ãƒƒãƒ—ãƒªã‚°ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆå®Œäº†"
    log_info "çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: $OUTPUT_DIR"
}

# ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
trap 'log_error "ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒç•°å¸¸çµ‚äº†ã—ã¾ã—ãŸ"; exit 1' ERR

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
main "$@"
