name: Comprehensive Test Suite

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  schedule:
    # æ¯æ—¥åˆå‰2æ™‚ï¼ˆUTCï¼‰ã«å®Ÿè¡Œ
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_mode:
        description: 'Test mode to run'
        required: true
        default: 'full'
        type: choice
        options:
          - quick
          - full
          - report-only
      generate_report:
        description: 'Generate detailed report'
        required: false
        default: true
        type: boolean

env:
  PYTHON_VERSION: '3.11'
  UV_VERSION: '0.4.18'
  COMPREHENSIVE_TEST_TIMEOUT: 1800  # 30åˆ†

jobs:
  # åŸºæœ¬çš„ãªç’°å¢ƒãƒã‚§ãƒƒã‚¯
  environment-check:
    name: Environment Check
    runs-on: ubuntu-latest
    outputs:
      python-version: ${{ steps.setup.outputs.python-version }}
      uv-version: ${{ steps.setup.outputs.uv-version }}
      docker-version: ${{ steps.setup.outputs.docker-version }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v5

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}

      - name: Check environment
        id: setup
        run: |
          echo "python-version=$(python --version)" >> $GITHUB_OUTPUT
          echo "uv-version=$(uv --version)" >> $GITHUB_OUTPUT
          echo "docker-version=$(docker --version)" >> $GITHUB_OUTPUT

          # åŸºæœ¬çš„ãªä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯
          python --version
          uv --version
          docker --version

          # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ãƒã‚§ãƒƒã‚¯
          ls -la
          test -f pyproject.toml
          test -d tests/
          test -f scripts/run-comprehensive-tests.sh

  # é…å¸ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆåŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ
  distribution-tests:
    name: Distribution Script Tests
    runs-on: ${{ matrix.os }}
    needs: environment-check
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest]
        test-type: [basic, extended]
      fail-fast: false
    steps:
      - name: Checkout code
        uses: actions/checkout@v5

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}

      - name: Install dependencies
        run: |
          uv sync
          uv run python -m pip install pytest pytest-timeout

      - name: Run distribution script tests
        timeout-minutes: 15
        run: |
          # é…å¸ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆã®åŸºæœ¬ãƒ†ã‚¹ãƒˆ
          uv run python -m pytest tests/test_comprehensive_distribution.py -v \
            --timeout=300 \
            --tb=short \
            -k "not (slow or integration)"

      - name: Run extended distribution tests
        if: matrix.test-type == 'extended'
        timeout-minutes: 20
        run: |
          # æ‹¡å¼µé…å¸ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ†ã‚¹ãƒˆ
          uv run python -m pytest tests/test_comprehensive_distribution.py -v \
            --timeout=600 \
            --tb=short

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: distribution-test-results-${{ matrix.os }}-${{ matrix.test-type }}
          path: |
            logs/
            output/test-reports/
          retention-days: 7

  # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´åˆæ€§ãƒ†ã‚¹ãƒˆ
  documentation-tests:
    name: Documentation Consistency Tests
    runs-on: ubuntu-latest
    needs: environment-check
    steps:
      - name: Checkout code
        uses: actions/checkout@v5

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}

      - name: Install dependencies
        run: |
          uv sync
          uv run python -m pip install pytest pytest-timeout requests pyyaml

      - name: Install additional tools
        run: |
          # shellcheck for shell script validation
          sudo apt-get update
          sudo apt-get install -y shellcheck

      - name: Run documentation consistency tests
        timeout-minutes: 10
        run: |
          uv run python -m pytest tests/test_documentation_consistency.py -v \
            --timeout=300 \
            --tb=short

      - name: Upload documentation test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: documentation-test-results
          path: |
            logs/
            output/test-reports/
          retention-days: 7

  # ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ãƒ†ã‚¹ãƒˆ
  user-experience-tests:
    name: End-to-End User Experience Tests
    runs-on: ${{ matrix.os }}
    needs: environment-check
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest]
        scenario: [new-user, existing-user, error-scenarios]
      fail-fast: false
    steps:
      - name: Checkout code
        uses: actions/checkout@v5

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}

      - name: Install dependencies
        run: |
          uv sync
          uv run python -m pip install pytest pytest-timeout

      - name: Run user experience tests
        timeout-minutes: 25
        env:
          NON_INTERACTIVE: '1'
          CI: 'true'
        run: |
          case "${{ matrix.scenario }}" in
            "new-user")
              uv run python -m pytest tests/test_end_to_end_user_experience.py::TestNewUserExperience -v \
                --timeout=600 --tb=short
              ;;
            "existing-user")
              uv run python -m pytest tests/test_end_to_end_user_experience.py::TestUserExperienceEdgeCases -v \
                --timeout=600 --tb=short
              ;;
            "error-scenarios")
              uv run python -m pytest tests/test_end_to_end_user_experience.py::TestUserExperienceAccessibility -v \
                --timeout=300 --tb=short
              ;;
          esac

      - name: Upload user experience test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: user-experience-test-results-${{ matrix.os }}-${{ matrix.scenario }}
          path: |
            logs/
            output/test-reports/
          retention-days: 7

  # çµ±åˆãƒ†ã‚¹ãƒˆ
  integration-tests:
    name: Comprehensive Integration Tests
    runs-on: ubuntu-latest
    needs: [environment-check, distribution-tests, documentation-tests]
    steps:
      - name: Checkout code
        uses: actions/checkout@v5

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}

      - name: Install dependencies
        run: |
          uv sync
          uv run python -m pip install pytest pytest-timeout

      - name: Run integration tests
        timeout-minutes: 30
        env:
          NON_INTERACTIVE: '1'
          CI: 'true'
          COMPREHENSIVE_TEST_TIMEOUT: 1800
        run: |
          uv run python -m pytest tests/test_comprehensive_integration_suite.py -v \
            --timeout=900 \
            --tb=short

      - name: Upload integration test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: integration-test-results
          path: |
            logs/
            output/test-reports/
          retention-days: 7

  # åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Ÿè¡Œ
  comprehensive-test-suite:
    name: Full Comprehensive Test Suite
    runs-on: ubuntu-latest
    needs: [distribution-tests, documentation-tests, user-experience-tests, integration-tests]
    if: github.event_name == 'schedule' || github.event.inputs.test_mode == 'full'
    steps:
      - name: Checkout code
        uses: actions/checkout@v5

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          version: ${{ env.UV_VERSION }}

      - name: Install dependencies
        run: |
          uv sync
          uv run python -m pip install pytest pytest-timeout

      - name: Run comprehensive test suite
        timeout-minutes: 45
        env:
          NON_INTERACTIVE: '1'
          CI: 'true'
          COMPREHENSIVE_TEST_TIMEOUT: 2700  # 45åˆ†
        run: |
          chmod +x scripts/run-comprehensive-tests.sh
          ./scripts/run-comprehensive-tests.sh --ci --report --output comprehensive-test-report.txt

      - name: Upload comprehensive test report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: comprehensive-test-report
          path: |
            comprehensive-test-report.txt
            logs/
            output/test-reports/
          retention-days: 30

  # ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼
  test-summary:
    name: Test Results Summary
    runs-on: ubuntu-latest
    needs: [distribution-tests, documentation-tests, user-experience-tests, integration-tests]
    if: always()
    steps:
      - name: Download all test results
        uses: actions/download-artifact@v4
        with:
          path: test-results/

      - name: Generate test summary
        run: |
          echo "# åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Ÿè¡Œçµæœ" > test-summary.md
          echo "" >> test-summary.md
          echo "## å®Ÿè¡Œæƒ…å ±" >> test-summary.md
          echo "- å®Ÿè¡Œæ™‚åˆ»: $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> test-summary.md
          echo "- ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼: ${{ github.workflow }}" >> test-summary.md
          echo "- ãƒˆãƒªã‚¬ãƒ¼: ${{ github.event_name }}" >> test-summary.md
          echo "- ãƒ–ãƒ©ãƒ³ãƒ: ${{ github.ref_name }}" >> test-summary.md
          echo "- ã‚³ãƒŸãƒƒãƒˆ: ${{ github.sha }}" >> test-summary.md
          echo "" >> test-summary.md

          echo "## ãƒ†ã‚¹ãƒˆçµæœ" >> test-summary.md
          echo "" >> test-summary.md

          # å„ã‚¸ãƒ§ãƒ–ã®çµæœã‚’ç¢ºèª
          echo "### é…å¸ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ†ã‚¹ãƒˆ" >> test-summary.md
          if [ "${{ needs.distribution-tests.result }}" = "success" ]; then
            echo "âœ… æˆåŠŸ" >> test-summary.md
          else
            echo "âŒ å¤±æ•— (${{ needs.distribution-tests.result }})" >> test-summary.md
          fi
          echo "" >> test-summary.md

          echo "### ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´åˆæ€§ãƒ†ã‚¹ãƒˆ" >> test-summary.md
          if [ "${{ needs.documentation-tests.result }}" = "success" ]; then
            echo "âœ… æˆåŠŸ" >> test-summary.md
          else
            echo "âŒ å¤±æ•— (${{ needs.documentation-tests.result }})" >> test-summary.md
          fi
          echo "" >> test-summary.md

          echo "### ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ãƒ†ã‚¹ãƒˆ" >> test-summary.md
          if [ "${{ needs.user-experience-tests.result }}" = "success" ]; then
            echo "âœ… æˆåŠŸ" >> test-summary.md
          else
            echo "âŒ å¤±æ•— (${{ needs.user-experience-tests.result }})" >> test-summary.md
          fi
          echo "" >> test-summary.md

          echo "### çµ±åˆãƒ†ã‚¹ãƒˆ" >> test-summary.md
          if [ "${{ needs.integration-tests.result }}" = "success" ]; then
            echo "âœ… æˆåŠŸ" >> test-summary.md
          else
            echo "âŒ å¤±æ•— (${{ needs.integration-tests.result }})" >> test-summary.md
          fi
          echo "" >> test-summary.md

          # å…¨ä½“çµæœã®åˆ¤å®š
          if [ "${{ needs.distribution-tests.result }}" = "success" ] && \
             [ "${{ needs.documentation-tests.result }}" = "success" ] && \
             [ "${{ needs.user-experience-tests.result }}" = "success" ] && \
             [ "${{ needs.integration-tests.result }}" = "success" ]; then
            echo "## ğŸ‰ å…¨ä½“çµæœ: æˆåŠŸ" >> test-summary.md
            echo "" >> test-summary.md
            echo "ã™ã¹ã¦ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸã€‚" >> test-summary.md
          else
            echo "## âš ï¸ å…¨ä½“çµæœ: ä¸€éƒ¨å¤±æ•—" >> test-summary.md
            echo "" >> test-summary.md
            echo "ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆã§å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚è©³ç´°ã¯å„ãƒ†ã‚¹ãƒˆçµæœã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚" >> test-summary.md
          fi

          echo "" >> test-summary.md
          echo "## ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆ" >> test-summary.md
          echo "- ãƒ†ã‚¹ãƒˆçµæœã®è©³ç´°ã¯ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™" >> test-summary.md
          echo "- ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ¬ãƒãƒ¼ãƒˆãŒå«ã¾ã‚Œã¦ã„ã¾ã™" >> test-summary.md

      - name: Upload test summary
        uses: actions/upload-artifact@v4
        with:
          name: test-summary
          path: test-summary.md
          retention-days: 30

      - name: Comment PR with test results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync('test-summary.md', 'utf8');

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });

  # å¤±æ•—æ™‚ã®é€šçŸ¥
  notify-failure:
    name: Notify Test Failure
    runs-on: ubuntu-latest
    needs: [distribution-tests, documentation-tests, user-experience-tests, integration-tests]
    if: failure() && (github.event_name == 'schedule' || github.ref == 'refs/heads/main')
    steps:
      - name: Create failure issue
        uses: actions/github-script@v7
        with:
          script: |
            const title = `åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå¤±æ•— - ${new Date().toISOString().split('T')[0]}`;
            const body = `
            ## åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ

            **å®Ÿè¡Œæƒ…å ±:**
            - ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼: ${{ github.workflow }}
            - å®Ÿè¡ŒID: ${{ github.run_id }}
            - ãƒ–ãƒ©ãƒ³ãƒ: ${{ github.ref_name }}
            - ã‚³ãƒŸãƒƒãƒˆ: ${{ github.sha }}
            - ãƒˆãƒªã‚¬ãƒ¼: ${{ github.event_name }}

            **å¤±æ•—ã—ãŸã‚¸ãƒ§ãƒ–:**
            - é…å¸ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ†ã‚¹ãƒˆ: ${{ needs.distribution-tests.result }}
            - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´åˆæ€§ãƒ†ã‚¹ãƒˆ: ${{ needs.documentation-tests.result }}
            - ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ãƒ†ã‚¹ãƒˆ: ${{ needs.user-experience-tests.result }}
            - çµ±åˆãƒ†ã‚¹ãƒˆ: ${{ needs.integration-tests.result }}

            **å¯¾å¿œãŒå¿…è¦ãªé …ç›®:**
            1. å¤±æ•—ã—ãŸãƒ†ã‚¹ãƒˆã®è©³ç´°ã‚’ç¢ºèª
            2. ãƒ­ã‚°ã¨ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚’åˆ†æ
            3. å¿…è¦ã«å¿œã˜ã¦ä¿®æ­£ã‚’å®Ÿæ–½
            4. ãƒ†ã‚¹ãƒˆã‚’å†å®Ÿè¡Œã—ã¦ç¢ºèª

            **é–¢é€£ãƒªãƒ³ã‚¯:**
            - [ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
            - [ã‚³ãƒŸãƒƒãƒˆè©³ç´°](${{ github.server_url }}/${{ github.repository }}/commit/${{ github.sha }})
            `;

            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: title,
              body: body,
              labels: ['bug', 'test-failure', 'comprehensive-tests']
            });
