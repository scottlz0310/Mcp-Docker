#!/usr/bin/env python3
"""
å®Œå…¨é…å¸ƒæ¤œè¨¼ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ

GitHub Actions Simulator Phase C ã®æœ€çµ‚çµ±åˆãƒ†ã‚¹ãƒˆã¨ã—ã¦ã€
æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ã‹ã‚‰é…å¸ƒãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®å®Œæˆåº¦ã¾ã§åŒ…æ‹¬çš„ã«æ¤œè¨¼ã—ã¾ã™ã€‚

Requirements: 5.1, 5.2, 5.3, 5.4, 5.5
"""

import os
import sys
import json
import subprocess
import tempfile
import shutil
import unittest
from pathlib import Path
from datetime import datetime
import logging

# ãƒ†ã‚¹ãƒˆç”¨ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)


class CompleteDistributionValidationTest(unittest.TestCase):
    """å®Œå…¨é…å¸ƒæ¤œè¨¼ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""

    @classmethod
    def setUpClass(cls):
        """ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹åˆæœŸåŒ–"""
        cls.project_root = Path(__file__).parent.parent
        cls.test_results = {
            "timestamp": datetime.utcnow().isoformat(),
            "test_summary": {},
            "detailed_results": {},
        }

        # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        os.makedirs(cls.project_root / "logs", exist_ok=True)

        logger.info("å®Œå…¨é…å¸ƒæ¤œè¨¼ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹")

    def setUp(self):
        """å„ãƒ†ã‚¹ãƒˆã®åˆæœŸåŒ–"""
        self.current_test = self._testMethodName
        logger.info(f"ãƒ†ã‚¹ãƒˆé–‹å§‹: {self.current_test}")

    def tearDown(self):
        """å„ãƒ†ã‚¹ãƒˆã®å¾Œå‡¦ç†"""
        logger.info(f"ãƒ†ã‚¹ãƒˆå®Œäº†: {self.current_test}")

    def test_01_essential_files_presence(self):
        """å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèªãƒ†ã‚¹ãƒˆ"""
        logger.info("å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ã‚’ç¢ºèªä¸­...")

        essential_files = [
            "README.md",
            "LICENSE",
            "CONTRIBUTING.md",
            "Makefile",
            "docker-compose.yml",
            ".env.example",
            "pyproject.toml",
        ]

        missing_files = []
        for file_path in essential_files:
            full_path = self.project_root / file_path
            if not full_path.exists():
                missing_files.append(file_path)

        self.assertEqual(len(missing_files), 0, f"å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«ãŒä¸è¶³: {missing_files}")

        logger.info("âœ… å…¨ã¦ã®å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨")

    def test_02_readme_quality_and_completeness(self):
        """README.md ã®å“è³ªã¨å®Œå…¨æ€§ãƒ†ã‚¹ãƒˆ"""
        logger.info("README.md ã®å“è³ªã‚’ç¢ºèªä¸­...")

        readme_path = self.project_root / "README.md"
        self.assertTrue(readme_path.exists(), "README.md ãŒå­˜åœ¨ã—ãªã„")

        content = readme_path.read_text(encoding="utf-8")

        # æœ€å°é™ã®å†…å®¹ç¢ºèª
        self.assertGreater(len(content), 1000, "README.md ã®å†…å®¹ãŒä¸ååˆ†")

        # å¿…è¦ãªã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ç¢ºèª
        required_sections = [
            ("ã‚¯ã‚¤ãƒƒã‚¯", "Quick"),  # ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ
            ("ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«", "install", "Install"),  # ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †
            ("ä½¿ç”¨", "ä½¿ã„æ–¹", "usage", "Usage"),  # ä½¿ç”¨æ–¹æ³•
            ("ä¾‹", "example", "Example"),  # ä¾‹
        ]

        for section_keywords in required_sections:
            section_found = any(keyword in content for keyword in section_keywords)
            self.assertTrue(section_found, f"README.md ã«å¿…è¦ãªã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒä¸è¶³: {section_keywords}")

        logger.info("âœ… README.md ã®å“è³ªãŒé©åˆ‡")

    def test_03_distribution_script_functionality(self):
        """é…å¸ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆã®æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
        logger.info("é…å¸ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆã®æ©Ÿèƒ½ã‚’ç¢ºèªä¸­...")

        run_actions_script = self.project_root / "scripts" / "run-actions.sh"
        self.assertTrue(run_actions_script.exists(), "run-actions.sh ãŒå­˜åœ¨ã—ãªã„")
        self.assertTrue(os.access(run_actions_script, os.X_OK), "run-actions.sh ãŒå®Ÿè¡Œä¸å¯")

        # ãƒ˜ãƒ«ãƒ—æ©Ÿèƒ½ã®ç¢ºèª
        try:
            result = subprocess.run(
                ["bash", str(run_actions_script), "--help"],
                capture_output=True,
                text=True,
                timeout=30,
                cwd=self.project_root,
            )

            # ãƒ˜ãƒ«ãƒ—ãŒè¡¨ç¤ºã•ã‚Œã‚‹ã‹ã€ã¾ãŸã¯é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã‚‹ã‹
            help_indicators = ["help", "usage", "ãƒ˜ãƒ«ãƒ—", "ä½¿ç”¨æ³•", "option"]
            help_found = any(
                indicator.lower() in result.stdout.lower() or indicator.lower() in result.stderr.lower()
                for indicator in help_indicators
            )

            self.assertTrue(help_found, "ãƒ˜ãƒ«ãƒ—æ©Ÿèƒ½ãŒé©åˆ‡ã«å‹•ä½œã—ãªã„")

        except subprocess.TimeoutExpired:
            self.fail("run-actions.sh ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
        except Exception as e:
            self.fail(f"run-actions.sh ã®å®Ÿè¡Œã§ã‚¨ãƒ©ãƒ¼: {e}")

        logger.info("âœ… é…å¸ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒé©åˆ‡ã«å‹•ä½œ")

    def test_04_documentation_consistency(self):
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´åˆæ€§ãƒ†ã‚¹ãƒˆ"""
        logger.info("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´åˆæ€§ã‚’ç¢ºèªä¸­...")

        # å¿…è¦ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
        required_docs = [
            "docs/TROUBLESHOOTING.md",
            "docs/actions/README.md",
            "docs/SUPPORT.md",
        ]

        existing_docs = []
        for doc_path in required_docs:
            full_path = self.project_root / doc_path
            if full_path.exists():
                existing_docs.append(doc_path)

        # æœ€ä½é™å¿…è¦ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒå­˜åœ¨ã™ã‚‹ã‹
        self.assertGreaterEqual(
            len(existing_docs),
            len(required_docs) * 0.7,  # 70%ä»¥ä¸Š
            f"å¿…è¦ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒä¸è¶³: å­˜åœ¨={len(existing_docs)}, å¿…è¦={len(required_docs)}",
        )

        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè¡Œ
        consistency_script = self.project_root / "scripts" / "check-docs-consistency.py"
        if consistency_script.exists():
            try:
                result = subprocess.run(
                    [sys.executable, str(consistency_script)],
                    capture_output=True,
                    text=True,
                    timeout=60,
                    cwd=self.project_root,
                )

                # ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒæ­£å¸¸çµ‚äº†ã™ã‚‹ã‹ã€è­¦å‘Šãƒ¬ãƒ™ãƒ«ã®ã‚¨ãƒ©ãƒ¼ã®ã¿ã‹
                self.assertIn(
                    result.returncode,
                    [0, 1],
                    f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã§é‡å¤§ãªã‚¨ãƒ©ãƒ¼: {result.stderr}",
                )

            except subprocess.TimeoutExpired:
                self.fail("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
            except Exception as e:
                logger.warning(f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")

        logger.info("âœ… ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´åˆæ€§ãŒé©åˆ‡")

    def test_05_template_files_validity(self):
        """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®æœ‰åŠ¹æ€§ãƒ†ã‚¹ãƒˆ"""
        logger.info("ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®æœ‰åŠ¹æ€§ã‚’ç¢ºèªä¸­...")

        template_files = {
            ".env.example": "text",
            ".pre-commit-config.yaml": "yaml",
            "docker-compose.override.yml.sample": "yaml",
        }

        existing_templates = 0

        for template_path, file_type in template_files.items():
            full_path = self.project_root / template_path

            if full_path.exists():
                existing_templates += 1

                # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã®åŸºæœ¬ç¢ºèª
                content = full_path.read_text(encoding="utf-8")
                self.assertGreater(len(content.strip()), 50, f"{template_path} ã®å†…å®¹ãŒä¸ååˆ†")

                # YAML ãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹æ–‡ç¢ºèª
                if file_type == "yaml":
                    try:
                        import yaml

                        yaml.safe_load(content)
                    except yaml.YAMLError as e:
                        self.fail(f"{template_path} ã®YAMLæ§‹æ–‡ã‚¨ãƒ©ãƒ¼: {e}")

        # æœ€ä½é™ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒå­˜åœ¨ã™ã‚‹ã‹
        self.assertGreaterEqual(
            existing_templates,
            len(template_files) * 0.6,  # 60%ä»¥ä¸Š
            f"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒä¸è¶³: å­˜åœ¨={existing_templates}, æœŸå¾…={len(template_files)}",
        )

        logger.info("âœ… ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒé©åˆ‡")

    def test_06_workflow_integration(self):
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµ±åˆãƒ†ã‚¹ãƒˆ"""
        logger.info("ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµ±åˆã‚’ç¢ºèªä¸­...")

        # Makefile ã®ç¢ºèª
        makefile_path = self.project_root / "Makefile"
        if makefile_path.exists():
            try:
                result = subprocess.run(
                    ["make", "help"],
                    capture_output=True,
                    text=True,
                    timeout=30,
                    cwd=self.project_root,
                )

                # make help ãŒå‹•ä½œã™ã‚‹ã‹
                self.assertIn(result.returncode, [0, 2], f"Makefile ã«å•é¡ŒãŒã‚ã‚‹: {result.stderr}")

            except subprocess.TimeoutExpired:
                self.fail("make help ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
            except FileNotFoundError:
                logger.warning("make ã‚³ãƒãƒ³ãƒ‰ãŒåˆ©ç”¨ã§ããªã„")

        # GitHub Actions ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ç¢ºèª
        workflows_dir = self.project_root / ".github" / "workflows"
        if workflows_dir.exists():
            workflow_files = list(workflows_dir.glob("*.yml")) + list(workflows_dir.glob("*.yaml"))

            self.assertGreater(len(workflow_files), 0, "GitHub Actions ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒå­˜åœ¨ã—ãªã„")

            # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã®åŸºæœ¬æ§‹æ–‡ç¢ºèª
            for workflow_file in workflow_files[:3]:  # æœ€åˆã®3ã¤ã‚’ãƒã‚§ãƒƒã‚¯
                try:
                    import yaml

                    content = workflow_file.read_text(encoding="utf-8")
                    workflow_data = yaml.safe_load(content)

                    # åŸºæœ¬çš„ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ§‹é€ ã®ç¢ºèª
                    if isinstance(workflow_data, dict):
                        self.assertIn(
                            "on",
                            workflow_data,
                            f"{workflow_file.name} ã«ãƒˆãƒªã‚¬ãƒ¼ãŒå®šç¾©ã•ã‚Œã¦ã„ãªã„",
                        )

                except yaml.YAMLError as e:
                    self.fail(f"{workflow_file.name} ã®YAMLæ§‹æ–‡ã‚¨ãƒ©ãƒ¼: {e}")

        logger.info("âœ… ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµ±åˆãŒé©åˆ‡")

    def test_07_platform_compatibility(self):
        """ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ äº’æ›æ€§ãƒ†ã‚¹ãƒˆ"""
        logger.info("ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ äº’æ›æ€§ã‚’ç¢ºèªä¸­...")

        # ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ¥ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ç¢ºèª
        install_scripts = [
            "scripts/install-linux.sh",
            "scripts/install-macos.sh",
            "scripts/install-windows.ps1",
        ]

        existing_scripts = 0
        for script_path in install_scripts:
            full_path = self.project_root / script_path
            if full_path.exists():
                existing_scripts += 1

                # ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®åŸºæœ¬ç¢ºèª
                content = full_path.read_text(encoding="utf-8")
                self.assertGreater(len(content.strip()), 100, f"{script_path} ã®å†…å®¹ãŒä¸ååˆ†")

        # æœ€ä½é™ã®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚µãƒãƒ¼ãƒˆ
        self.assertGreaterEqual(
            existing_scripts,
            2,
            f"ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ¥ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒä¸è¶³: å­˜åœ¨={existing_scripts}",
        )

        # ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚µãƒãƒ¼ãƒˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ç¢ºèª
        platform_doc = self.project_root / "docs" / "PLATFORM_SUPPORT.md"
        if platform_doc.exists():
            content = platform_doc.read_text(encoding="utf-8")
            platforms = ["Linux", "macOS", "Windows"]

            supported_platforms = sum(1 for platform in platforms if platform in content)

            self.assertGreaterEqual(
                supported_platforms,
                2,
                f"ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚µãƒãƒ¼ãƒˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒä¸ååˆ†: {supported_platforms}/3",
            )

        logger.info("âœ… ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ äº’æ›æ€§ãŒé©åˆ‡")

    def test_08_new_user_experience_simulation(self):
        """æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ"""
        logger.info("æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¸­...")

        # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ç’°å¢ƒã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_project_dir = Path(temp_dir) / "github-actions-simulator"

            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚³ãƒ”ãƒ¼ï¼ˆ.git ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯é™¤å¤–ï¼‰
            shutil.copytree(
                self.project_root,
                temp_project_dir,
                ignore=shutil.ignore_patterns(".git", "__pycache__", "*.pyc", ".pytest_cache"),
            )

            # æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã—ã¦ã®åŸºæœ¬æ“ä½œãƒ†ã‚¹ãƒˆ

            # 1. README.md ã®å¯èª­æ€§
            readme_path = temp_project_dir / "README.md"
            self.assertTrue(readme_path.exists(), "README.md ãŒå­˜åœ¨ã—ãªã„")

            readme_content = readme_path.read_text(encoding="utf-8")
            self.assertGreater(len(readme_content), 500, "README.md ãŒçŸ­ã™ãã‚‹")

            # 2. åŸºæœ¬çš„ãªè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨
            essential_config_files = [".env.example", "docker-compose.yml"]
            for config_file in essential_config_files:
                config_path = temp_project_dir / config_file
                self.assertTrue(config_path.exists(), f"{config_file} ãŒå­˜åœ¨ã—ãªã„")

            # 3. å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆã®åŸºæœ¬å‹•ä½œç¢ºèª
            run_script = temp_project_dir / "scripts" / "run-actions.sh"
            if run_script.exists() and os.access(run_script, os.X_OK):
                try:
                    # æ§‹æ–‡ãƒã‚§ãƒƒã‚¯
                    result = subprocess.run(
                        ["bash", "-n", str(run_script)],
                        capture_output=True,
                        text=True,
                        timeout=10,
                    )
                    self.assertEqual(
                        result.returncode,
                        0,
                        f"run-actions.sh ã«æ§‹æ–‡ã‚¨ãƒ©ãƒ¼: {result.stderr}",
                    )

                except subprocess.TimeoutExpired:
                    self.fail("run-actions.sh ã®æ§‹æ–‡ãƒã‚§ãƒƒã‚¯ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")

        logger.info("âœ… æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æˆåŠŸ")

    def test_09_security_and_license_compliance(self):
        """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨ãƒ©ã‚¤ã‚»ãƒ³ã‚¹æº–æ‹ ãƒ†ã‚¹ãƒˆ"""
        logger.info("ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨ãƒ©ã‚¤ã‚»ãƒ³ã‚¹æº–æ‹ ã‚’ç¢ºèªä¸­...")

        # ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
        license_path = self.project_root / "LICENSE"
        self.assertTrue(license_path.exists(), "LICENSE ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„")

        license_content = license_path.read_text(encoding="utf-8")
        self.assertGreater(len(license_content), 100, "LICENSE ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ãŒä¸ååˆ†")

        # .gitignore ã®ç¢ºèª
        gitignore_path = self.project_root / ".gitignore"
        if gitignore_path.exists():
            gitignore_content = gitignore_path.read_text(encoding="utf-8")

            # é‡è¦ãªé™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç¢ºèª
            important_patterns = [".env", "secret", "key", "__pycache__"]
            for pattern in important_patterns:
                if pattern not in gitignore_content:
                    logger.warning(f".gitignore ã« {pattern} ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒä¸è¶³")

        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®šã®ç¢ºèª
        security_files = [
            ".github/workflows/security-scan.yml.sample",
            "scripts/run_security_scan.py",
        ]

        security_setup = sum(1 for file_path in security_files if (self.project_root / file_path).exists())

        self.assertGreater(security_setup, 0, "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³è¨­å®šãŒä¸è¶³")

        logger.info("âœ… ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨ãƒ©ã‚¤ã‚»ãƒ³ã‚¹æº–æ‹ ãŒé©åˆ‡")

    def test_10_ci_cd_pipeline_readiness(self):
        """CI/CD ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æº–å‚™çŠ¶æ³ãƒ†ã‚¹ãƒˆ"""
        logger.info("CI/CD ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æº–å‚™çŠ¶æ³ã‚’ç¢ºèªä¸­...")

        workflows_dir = self.project_root / ".github" / "workflows"
        self.assertTrue(
            workflows_dir.exists(),
            "GitHub Actions ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„",
        )

        # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
        workflow_files = list(workflows_dir.glob("*.yml")) + list(workflows_dir.glob("*.yaml"))
        self.assertGreater(len(workflow_files), 0, "ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„")

        # é‡è¦ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ç¢ºèª
        important_workflows = ["ci.yml", "quality-gates.yml"]
        existing_important = sum(1 for workflow in important_workflows if (workflows_dir / workflow).exists())

        self.assertGreater(existing_important, 0, "é‡è¦ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒä¸è¶³")

        # å“è³ªã‚²ãƒ¼ãƒˆè¨­å®šã®ç¢ºèª
        quality_scripts = [
            "scripts/automated-quality-check.sh",
            "scripts/run-comprehensive-tests.sh",
        ]

        quality_setup = sum(1 for script_path in quality_scripts if (self.project_root / script_path).exists())

        self.assertGreater(quality_setup, 0, "å“è³ªã‚²ãƒ¼ãƒˆè¨­å®šãŒä¸è¶³")

        logger.info("âœ… CI/CD ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æº–å‚™ãŒé©åˆ‡")

    def test_11_comprehensive_integration_validation(self):
        """åŒ…æ‹¬çš„çµ±åˆæ¤œè¨¼ãƒ†ã‚¹ãƒˆ"""
        logger.info("åŒ…æ‹¬çš„çµ±åˆæ¤œè¨¼ã‚’å®Ÿè¡Œä¸­...")

        # æœ€çµ‚çµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè¡Œ
        final_validation_script = self.project_root / "tests" / "test_final_integration_validation.py"
        if final_validation_script.exists():
            try:
                result = subprocess.run(
                    [sys.executable, str(final_validation_script)],
                    capture_output=True,
                    text=True,
                    timeout=120,
                    cwd=self.project_root,
                )

                # ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒæ­£å¸¸çµ‚äº†ã™ã‚‹ã‹ã€è»½å¾®ãªã‚¨ãƒ©ãƒ¼ã®ã¿ã‹
                self.assertIn(
                    result.returncode,
                    [0, 1],
                    f"æœ€çµ‚çµ±åˆãƒ†ã‚¹ãƒˆã§é‡å¤§ãªã‚¨ãƒ©ãƒ¼: {result.stderr}",
                )

            except subprocess.TimeoutExpired:
                self.fail("æœ€çµ‚çµ±åˆãƒ†ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
            except Exception as e:
                logger.warning(f"æœ€çµ‚çµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")

        # é…å¸ƒæ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè¡Œ
        distribution_validation_script = self.project_root / "scripts" / "final-distribution-validation.sh"
        if distribution_validation_script.exists() and os.access(distribution_validation_script, os.X_OK):
            try:
                result = subprocess.run(
                    ["bash", str(distribution_validation_script)],
                    capture_output=True,
                    text=True,
                    timeout=180,
                    cwd=self.project_root,
                )

                # ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒæ­£å¸¸çµ‚äº†ã™ã‚‹ã‹ã€è»½å¾®ãªã‚¨ãƒ©ãƒ¼ã®ã¿ã‹
                self.assertIn(
                    result.returncode,
                    [0, 1],
                    f"é…å¸ƒæ¤œè¨¼ã§é‡å¤§ãªã‚¨ãƒ©ãƒ¼: {result.stderr}",
                )

            except subprocess.TimeoutExpired:
                self.fail("é…å¸ƒæ¤œè¨¼ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
            except Exception as e:
                logger.warning(f"é…å¸ƒæ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")

        logger.info("âœ… åŒ…æ‹¬çš„çµ±åˆæ¤œè¨¼æˆåŠŸ")

    @classmethod
    def tearDownClass(cls):
        """ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹çµ‚äº†å‡¦ç†"""
        # ãƒ†ã‚¹ãƒˆçµæœã®ä¿å­˜
        results_file = cls.project_root / "complete_distribution_validation_results.json"

        cls.test_results["completion_timestamp"] = datetime.utcnow().isoformat()

        with open(results_file, "w", encoding="utf-8") as f:
            json.dump(cls.test_results, f, ensure_ascii=False, indent=2)

        logger.info(f"å®Œå…¨é…å¸ƒæ¤œè¨¼ãƒ†ã‚¹ãƒˆå®Œäº† - çµæœ: {results_file}")


def run_validation_suite():
    """æ¤œè¨¼ã‚¹ã‚¤ãƒ¼ãƒˆã®å®Ÿè¡Œ"""
    # ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆã®ä½œæˆ
    suite = unittest.TestLoader().loadTestsFromTestCase(CompleteDistributionValidationTest)

    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    runner = unittest.TextTestRunner(verbosity=2, stream=sys.stdout, buffer=True)

    result = runner.run(suite)

    # çµæœã®è©•ä¾¡
    if result.wasSuccessful():
        print("\n" + "=" * 60)
        print("ğŸ‰ å®Œå…¨é…å¸ƒæ¤œè¨¼ãƒ†ã‚¹ãƒˆ - å…¨ã¦æˆåŠŸ!")
        print("é…å¸ƒãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®æº–å‚™ãŒå®Œäº†ã—ã¦ã„ã¾ã™ã€‚")
        print("=" * 60)
        return 0
    else:
        print("\n" + "=" * 60)
        print("âš ï¸  å®Œå…¨é…å¸ƒæ¤œè¨¼ãƒ†ã‚¹ãƒˆ - ä¸€éƒ¨å¤±æ•—")
        print(f"å¤±æ•—: {len(result.failures)}, ã‚¨ãƒ©ãƒ¼: {len(result.errors)}")
        print("é…å¸ƒå‰ã«å•é¡Œã‚’è§£æ±ºã—ã¦ãã ã•ã„ã€‚")
        print("=" * 60)
        return 1


if __name__ == "__main__":
    sys.exit(run_validation_suite())
